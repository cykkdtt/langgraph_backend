# LangMem é›†æˆæŒ‡å—

## æ¦‚è¿°

LangMem æ˜¯ LangChain ç”Ÿæ€ç³»ç»Ÿä¸­çš„è®°å¿†ç®¡ç†ç»„ä»¶ï¼Œä¸“ä¸º LangGraph åº”ç”¨è®¾è®¡ï¼Œæä¾›æ™ºèƒ½ä½“çš„é•¿æœŸè®°å¿†å­˜å‚¨å’Œæ£€ç´¢èƒ½åŠ›ã€‚æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨å¤šæ™ºèƒ½ä½“åä½œå¹³å°ä¸­é›†æˆ LangMemã€‚

## æ ¸å¿ƒç‰¹æ€§

### 1. è®°å¿†ç±»å‹æ”¯æŒ
- **è¯­ä¹‰è®°å¿†**: å­˜å‚¨æ¦‚å¿µã€äº‹å®å’ŒçŸ¥è¯†
- **æƒ…èŠ‚è®°å¿†**: å­˜å‚¨å…·ä½“çš„äº¤äº’å†å²å’Œäº‹ä»¶
- **ç¨‹åºè®°å¿†**: å­˜å‚¨æŠ€èƒ½ã€ç­–ç•¥å’Œè¡Œä¸ºæ¨¡å¼

### 2. æ™ºèƒ½è®°å¿†ç®¡ç†
- è‡ªåŠ¨è®°å¿†æå–å’Œå­˜å‚¨
- è¯­ä¹‰æœç´¢å’Œç²¾ç¡®åŒ¹é…
- è®°å¿†æ•´åˆå’Œä¼˜åŒ–
- å‘½åç©ºé—´éš”ç¦»

### 3. LangGraph åŸç”Ÿé›†æˆ
- ä¸ LangGraph Store æ— ç¼é›†æˆ
- æ”¯æŒæ£€æŸ¥ç‚¹ç³»ç»Ÿ
- çŠ¶æ€æŒä¹…åŒ–

## å®‰è£…å’Œé…ç½®

### 1. ä¾èµ–å®‰è£…

```bash
pip install langmem langgraph[store] psycopg2-binary redis
```

### 2. ç¯å¢ƒé…ç½®

```python
# config/memory_config.py
import os
from typing import Optional, Literal
from pydantic import Field
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ Pydantic
try:
    from pydantic_settings import BaseSettings
except ImportError:
    from pydantic import BaseSettings

class MemoryConfig(BaseSettings):
    # å­˜å‚¨é…ç½®
    store_type: Literal["postgres", "memory"] = Field(
        default="postgres", 
        description="å­˜å‚¨ç±»å‹ï¼špostgres æˆ– memory"
    )
    postgres_url: str = Field(
        default_factory=lambda: os.getenv(
            "POSTGRES_URI", 
            os.getenv("LANGMEM_POSTGRES_URL", "postgresql://user:pass@localhost:5432/langmem")
        ),
        description="PostgreSQL è¿æ¥URL"
    )
    
    # åµŒå…¥æ¨¡å‹é…ç½®ï¼ˆé˜¿é‡Œäº‘DashScopeï¼‰
    embedding_model: str = Field(
        default_factory=lambda: os.getenv("LLM_EMBEDDING_MODEL", "openai:text-embedding-v4"),
        description="åµŒå…¥æ¨¡å‹åç§°ï¼ˆé˜¿é‡Œäº‘DashScope text-embedding-v4ï¼‰"
    )
    embedding_dims: int = Field(
        default_factory=lambda: int(os.getenv("LLM_EMBEDDING_DIMENSIONS", "1024")),
        description="åµŒå…¥å‘é‡ç»´åº¦ï¼ˆtext-embedding-v4ä¸º1024ç»´ï¼‰"
    )
    
    # è®°å¿†ç®¡ç†é…ç½®
    max_memories_per_namespace: int = 10000
    auto_consolidate: bool = True
    consolidate_threshold: int = 1000
    
    # ç¼“å­˜é…ç½®
    redis_url: Optional[str] = "redis://localhost:6379/0"
    cache_ttl: int = 3600
    
    # æ¸…ç†é…ç½®
    cleanup_interval: int = 86400  # 24å°æ—¶
    backup_enabled: bool = True
    backup_interval: int = 604800  # 7å¤©

memory_config = MemoryConfig()
```

## æ ¸å¿ƒç»„ä»¶é›†æˆ

### 1. è®°å¿†å­˜å‚¨ç®¡ç†å™¨

```python
# core/memory/store_manager.py
import os
import logging
from typing import Optional, Dict, Any
from langgraph.store.postgres import PostgresStore
from langgraph.store.memory import InMemoryStore
from langgraph.store.base import BaseStore
from langchain_community.embeddings import DashScopeEmbeddings
from langmem import create_memory_store_manager
from config.memory_config import memory_config

logger = logging.getLogger(__name__)

def create_embeddings():
    """åˆ›å»ºåµŒå…¥æ¨¡å‹å®ä¾‹"""
    embedding_model = memory_config.embedding_model
    
    if embedding_model.startswith("openai:text-embedding-v"):
        # ä½¿ç”¨é˜¿é‡Œäº‘DashScopeåµŒå…¥æ¨¡å‹
        model_name = embedding_model.split(":", 1)[1]  # æå–æ¨¡å‹åç§°
        return DashScopeEmbeddings(
            model=model_name,
            dashscope_api_key=os.getenv("DASHSCOPE_API_KEY")
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„åµŒå…¥æ¨¡å‹: {embedding_model}")

class MemoryStoreManager:
    def __init__(self):
        self.store: Optional[BaseStore] = None
        self.memory_manager = None
        self._initialized = False
        self._store_context = None
    
    async def initialize(self) -> None:
        """åˆå§‹åŒ–å­˜å‚¨ç³»ç»Ÿ"""
        if self._initialized:
            return
        
        try:
            # åˆ›å»ºåµŒå…¥æ¨¡å‹å®ä¾‹
            embeddings = create_embeddings()
            
            # åˆ›å»ºå­˜å‚¨å®ä¾‹
            if memory_config.store_type == "postgres":
                # ä½¿ç”¨from_conn_stringåˆ›å»ºPostgresStoreä¸Šä¸‹æ–‡ç®¡ç†å™¨
                self._store_context = PostgresStore.from_conn_string(
                    memory_config.postgres_url,
                    index={
                        "embed": embeddings,  # ä½¿ç”¨DashScopeEmbeddingså®ä¾‹
                        "dims": memory_config.embedding_dims,
                        "fields": ["$"]  # å¯¹æ‰€æœ‰å­—æ®µè¿›è¡Œå‘é‡åŒ–
                    }
                )
                self.store = self._store_context.__enter__()
                logger.info("ä½¿ç”¨ PostgreSQL å­˜å‚¨")
            else:
                self.store = InMemoryStore(
                    index={
                        "embed": embeddings,  # ä½¿ç”¨DashScopeEmbeddingså®ä¾‹
                        "dims": memory_config.embedding_dims,
                        "fields": ["$"]  # å¯¹æ‰€æœ‰å­—æ®µè¿›è¡Œå‘é‡åŒ–
                    }
                )
                self._store_context = None
                logger.info("ä½¿ç”¨å†…å­˜å­˜å‚¨")
            
            # è®¾ç½®å­˜å‚¨
            if hasattr(self.store, 'setup'):
                await self.store.setup()
            
            # åˆ›å»ºè®°å¿†å­˜å‚¨ç®¡ç†å™¨
            self.memory_manager = create_memory_store_manager(
                store=self.store,
                namespace_prefix=memory_config.namespace_prefix
            )
            
            self._initialized = True
            logger.info("è®°å¿†å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è®°å¿†å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # å¦‚æœæ˜¯PostgresStoreï¼Œéœ€è¦é€€å‡ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
            if self._store_context:
                self._store_context.__exit__(None, None, None)
                logger.info("PostgreSQLå­˜å‚¨ä¸Šä¸‹æ–‡å·²å…³é—­")
            elif self.store and hasattr(self.store, 'close'):
                await self.store.close()
                logger.info("è®°å¿†å­˜å‚¨è¿æ¥å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­å­˜å‚¨è¿æ¥æ—¶å‡ºé”™: {e}")
        
        self._initialized = False
    
    def get_namespace(self, agent_id: str, session_id: str) -> str:
        """ç”Ÿæˆå‘½åç©ºé—´"""
        return f"agent_{agent_id}_session_{session_id}"

# å…¨å±€å®ä¾‹
memory_store_manager = MemoryStoreManager()
```

### 2. è®°å¿†å·¥å…·åˆ›å»ºå™¨

```python
# app/core/memory/tools.py
from langmem import create_manage_memory_tool, create_search_memory_tool
from typing import List, Dict, Any
from app.core.memory.store_manager import memory_store_manager

class MemoryToolsFactory:
    @staticmethod
    def create_memory_tools(namespace: str) -> List[Dict[str, Any]]:
        """ä¸ºæŒ‡å®šå‘½åç©ºé—´åˆ›å»ºè®°å¿†å·¥å…·"""
        
        # åˆ›å»ºè®°å¿†ç®¡ç†å·¥å…·
        manage_tool = create_manage_memory_tool(
            store=memory_store_manager.store,
            namespace=namespace
        )
        
        # åˆ›å»ºè®°å¿†æœç´¢å·¥å…·
        search_tool = create_search_memory_tool(
            store=memory_store_manager.store,
            namespace=namespace
        )
        
        return [manage_tool, search_tool]
    
    @staticmethod
    def create_semantic_memory_tool(namespace: str):
        """åˆ›å»ºè¯­ä¹‰è®°å¿†å·¥å…·"""
        return create_manage_memory_tool(
            store=memory_store_manager.store,
            namespace=f"{namespace}_semantic",
            memory_type="semantic"
        )
    
    @staticmethod
    def create_episodic_memory_tool(namespace: str):
        """åˆ›å»ºæƒ…èŠ‚è®°å¿†å·¥å…·"""
        return create_manage_memory_tool(
            store=memory_store_manager.store,
            namespace=f"{namespace}_episodic",
            memory_type="episodic"
        )
    
    @staticmethod
    def create_procedural_memory_tool(namespace: str):
        """åˆ›å»ºç¨‹åºè®°å¿†å·¥å…·"""
        return create_manage_memory_tool(
            store=memory_store_manager.store,
            namespace=f"{namespace}_procedural",
            memory_type="procedural"
        )
```

### 3. è®°å¿†å¢å¼ºçš„æ™ºèƒ½ä½“åŸºç±»

```python
# app/agents/memory_enhanced_base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from langgraph import StateGraph
from app.core.memory.tools import MemoryToolsFactory
from app.core.memory.store_manager import memory_store_manager
from app.agents.base import BaseAgent

class MemoryEnhancedAgent(BaseAgent, ABC):
    def __init__(self, agent_id: str, config: Dict[str, Any]):
        super().__init__(agent_id, config)
        self.memory_namespace = None
        self.memory_tools = []
    
    async def setup_memory(self, session_id: str):
        """è®¾ç½®è®°å¿†ç³»ç»Ÿ"""
        self.memory_namespace = memory_store_manager.get_namespace(
            self.agent_id, session_id
        )
        
        # åˆ›å»ºè®°å¿†å·¥å…·
        self.memory_tools = MemoryToolsFactory.create_memory_tools(
            self.memory_namespace
        )
        
        # æ·»åŠ åˆ°æ™ºèƒ½ä½“å·¥å…·åˆ—è¡¨
        self.tools.extend(self.memory_tools)
    
    async def search_memories(self, query: str, memory_type: Optional[str] = None) -> List[Dict]:
        """æœç´¢è®°å¿†"""
        search_namespace = self.memory_namespace
        if memory_type:
            search_namespace = f"{self.memory_namespace}_{memory_type}"
        
        search_tool = MemoryToolsFactory.create_search_memory_tool(search_namespace)
        return await search_tool.ainvoke({"query": query})
    
    async def store_memory(self, content: str, memory_type: str = "semantic", 
                          metadata: Optional[Dict] = None):
        """å­˜å‚¨è®°å¿†"""
        namespace = f"{self.memory_namespace}_{memory_type}"
        manage_tool = MemoryToolsFactory.create_manage_memory_tool(namespace)
        
        memory_data = {
            "content": content,
            "metadata": metadata or {}
        }
        
        return await manage_tool.ainvoke({
            "action": "create",
            "memory": memory_data
        })
    
    async def inject_memory_context(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """æ³¨å…¥è®°å¿†ä¸Šä¸‹æ–‡"""
        if "messages" in state and state["messages"]:
            last_message = state["messages"][-1]
            
            # æœç´¢ç›¸å…³è®°å¿†
            relevant_memories = await self.search_memories(
                query=last_message.content,
                memory_type="semantic"
            )
            
            # å°†è®°å¿†æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            if relevant_memories:
                memory_context = "\n".join([
                    f"è®°å¿†: {mem['content']}" for mem in relevant_memories[:3]
                ])
                state["memory_context"] = memory_context
        
        return state
    
    async def update_memory_background(self, interaction_data: Dict[str, Any]):
        """åå°æ›´æ–°è®°å¿†"""
        # æå–å…³é”®ä¿¡æ¯å­˜å‚¨ä¸ºè¯­ä¹‰è®°å¿†
        if "key_insights" in interaction_data:
            await self.store_memory(
                content=interaction_data["key_insights"],
                memory_type="semantic",
                metadata={"timestamp": interaction_data.get("timestamp")}
            )
        
        # å­˜å‚¨å®Œæ•´äº¤äº’ä¸ºæƒ…èŠ‚è®°å¿†
        if "full_interaction" in interaction_data:
            await self.store_memory(
                content=interaction_data["full_interaction"],
                memory_type="episodic",
                metadata={
                    "session_id": interaction_data.get("session_id"),
                    "timestamp": interaction_data.get("timestamp")
                }
            )
```

## ğŸš€ æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½

### æ¦‚è¿°

LangMemçš„æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå¯ä»¥åŸºäºç”¨æˆ·åé¦ˆå’Œå¯¹è¯å†å²è‡ªåŠ¨æ”¹è¿›æ™ºèƒ½ä½“çš„æç¤ºè¯ã€‚è¿™ä¸ªåŠŸèƒ½å¯ä»¥æ˜¾è‘—æå‡æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ€§èƒ½å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚

### æ ¸å¿ƒç»„ä»¶

#### 1. æç¤ºè¯ä¼˜åŒ–å™¨ (PromptOptimizer)

```python
# core/optimization/prompt_optimizer.py
from typing import Dict, Any, List, Optional
from langmem import optimize_prompt
from core.memory.store_manager import memory_store_manager

class PromptOptimizer:
    """æç¤ºè¯ä¼˜åŒ–å™¨"""
    
    def __init__(self, memory_manager):
        self.memory_manager = memory_manager
        self.model_name = "anthropic:claude-3-5-sonnet-latest"
        self.optimization_namespace = "prompt_optimization"
        
    async def initialize(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        await self.memory_manager.initialize()
    
    async def optimize_agent_prompt(self, agent_type: str, current_prompt: str, 
                                  min_feedback_count: int = 10) -> Optional[str]:
        """ä¼˜åŒ–å•ä¸ªæ™ºèƒ½ä½“çš„æç¤ºè¯"""
        
        # 1. æ”¶é›†åé¦ˆæ•°æ®
        feedback_data = await self._collect_feedback_data(agent_type, min_feedback_count)
        
        if not feedback_data or len(feedback_data) < min_feedback_count:
            return None
        
        # 2. åˆ†æåé¦ˆæ¨¡å¼
        feedback_analysis = await self._analyze_feedback_patterns(feedback_data)
        
        # 3. ä½¿ç”¨LangMemä¼˜åŒ–æç¤ºè¯
        optimized_prompt = await optimize_prompt(
            store=self.memory_manager.store,
            namespace=f"{self.optimization_namespace}_{agent_type}",
            current_prompt=current_prompt,
            feedback_data=feedback_analysis,
            model=self.model_name
        )
        
        # 4. å­˜å‚¨ä¼˜åŒ–å†å²
        await self._store_optimization_history(agent_type, current_prompt, optimized_prompt, feedback_analysis)
        
        return optimized_prompt
    
    async def optimize_multi_agent_system(self, agent_prompts: Dict[str, str]) -> Dict[str, str]:
        """ä¼˜åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åä½œæ•ˆæœ"""
        
        # 1. åˆ†æå›¢é˜Ÿåä½œæ¨¡å¼
        collaboration_patterns = await self._analyze_collaboration_patterns(agent_prompts.keys())
        
        # 2. ä¼˜åŒ–æ¯ä¸ªæ™ºèƒ½ä½“çš„æç¤ºè¯
        optimized_prompts = {}
        for agent_type, current_prompt in agent_prompts.items():
            # è€ƒè™‘åä½œä¸Šä¸‹æ–‡çš„ä¼˜åŒ–
            optimized = await self._optimize_with_collaboration_context(
                agent_type, current_prompt, collaboration_patterns
            )
            optimized_prompts[agent_type] = optimized or current_prompt
        
        return optimized_prompts
    
    async def _collect_feedback_data(self, agent_type: str, min_count: int) -> List[Dict[str, Any]]:
        """æ”¶é›†åé¦ˆæ•°æ®"""
        feedback_namespace = f"feedback_{agent_type}"
        
        # ä»è®°å¿†å­˜å‚¨ä¸­æœç´¢åé¦ˆæ•°æ®
        feedback_memories = await self.memory_manager.search_memories(
            query="ç”¨æˆ·åé¦ˆ æ»¡æ„åº¦",
            namespace=feedback_namespace,
            limit=min_count * 2
        )
        
        return [memory.content for memory in feedback_memories[:min_count]]
    
    async def _analyze_feedback_patterns(self, feedback_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æåé¦ˆæ¨¡å¼"""
        # è®¡ç®—å¹³å‡æ»¡æ„åº¦
        satisfaction_scores = [fb.get("satisfaction_score", 0) for fb in feedback_data]
        avg_satisfaction = sum(satisfaction_scores) / len(satisfaction_scores) if satisfaction_scores else 0
        
        # æå–å¸¸è§é—®é¢˜å’Œå»ºè®®
        common_issues = []
        improvement_suggestions = []
        
        for feedback in feedback_data:
            if feedback.get("feedback_text"):
                if feedback.get("satisfaction_score", 0) < 0.6:
                    common_issues.append(feedback["feedback_text"])
                else:
                    improvement_suggestions.append(feedback["feedback_text"])
        
        return {
            "avg_satisfaction": avg_satisfaction,
            "total_feedback_count": len(feedback_data),
            "common_issues": common_issues,
            "improvement_suggestions": improvement_suggestions
        }
    
    async def _store_optimization_history(self, agent_type: str, original_prompt: str, 
                                        optimized_prompt: str, analysis: Dict[str, Any]):
        """å­˜å‚¨ä¼˜åŒ–å†å²"""
        history_data = {
            "agent_type": agent_type,
            "original_prompt": original_prompt,
            "optimized_prompt": optimized_prompt,
            "optimization_analysis": analysis,
            "timestamp": datetime.now().isoformat()
        }
        
        await self.memory_manager.store_memory(
            content=f"æç¤ºè¯ä¼˜åŒ–: {agent_type}",
            memory_type="procedural",
            namespace=f"{self.optimization_namespace}_history",
            metadata=history_data
        )
```

#### 2. åé¦ˆæ”¶é›†å™¨ (FeedbackCollector)

```python
class FeedbackCollector:
    """ç”¨æˆ·åé¦ˆæ”¶é›†å™¨"""
    
    def __init__(self, prompt_optimizer: PromptOptimizer):
        self.prompt_optimizer = prompt_optimizer
        self.feedback_namespace = "prompt_feedback"
    
    async def collect_user_feedback(self, conversation_id: str, messages: List[Message],
                                  satisfaction_score: float, feedback_text: str = "",
                                  agent_type: str = "default"):
        """æ”¶é›†ç”¨æˆ·åé¦ˆ"""
        
        feedback_data = {
            "conversation_id": conversation_id,
            "agent_type": agent_type,
            "satisfaction_score": satisfaction_score,
            "feedback_text": feedback_text,
            "message_count": len(messages),
            "timestamp": datetime.now().isoformat()
        }
        
        # å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ
        await self.prompt_optimizer.memory_manager.store_memory(
            content=f"ç”¨æˆ·åé¦ˆ: æ»¡æ„åº¦{satisfaction_score} - {feedback_text}",
            memory_type="episodic",
            namespace=f"feedback_{agent_type}",
            metadata=feedback_data
        )
    
    async def collect_improvement_suggestion(self, agent_type: str, suggestion: str,
                                           context: Dict[str, Any] = None):
        """æ”¶é›†æ”¹è¿›å»ºè®®"""
        
        suggestion_data = {
            "agent_type": agent_type,
            "suggestion": suggestion,
            "context": context or {},
            "timestamp": datetime.now().isoformat()
        }
        
        await self.prompt_optimizer.memory_manager.store_memory(
            content=f"æ”¹è¿›å»ºè®®: {suggestion}",
            memory_type="semantic",
            namespace=f"suggestions_{agent_type}",
            metadata=suggestion_data
        )
```

#### 3. è‡ªåŠ¨ä¼˜åŒ–è°ƒåº¦å™¨ (AutoOptimizationScheduler)

```python
class AutoOptimizationScheduler:
    """è‡ªåŠ¨ä¼˜åŒ–è°ƒåº¦å™¨"""
    
    def __init__(self, prompt_optimizer: PromptOptimizer):
        self.prompt_optimizer = prompt_optimizer
        self.config = {
            "enabled": False,
            "interval_hours": 24,
            "min_feedback_count": 10,
            "optimization_strategy": "gradient"
        }
        self.is_running = False
        self.last_optimization = {}
    
    async def configure_auto_optimization(self, config: Dict[str, Any]):
        """é…ç½®è‡ªåŠ¨ä¼˜åŒ–"""
        self.config.update(config)
    
    async def run_optimization_cycle(self, agent_configs: Dict[str, str]) -> Dict[str, str]:
        """è¿è¡Œä¼˜åŒ–å‘¨æœŸ"""
        if self.is_running:
            return agent_configs
        
        self.is_running = True
        optimized_configs = {}
        
        try:
            for agent_type, current_prompt in agent_configs.items():
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
                if await self._should_optimize(agent_type):
                    optimized = await self.prompt_optimizer.optimize_agent_prompt(
                        agent_type=agent_type,
                        current_prompt=current_prompt,
                        min_feedback_count=self.config["min_feedback_count"]
                    )
                    optimized_configs[agent_type] = optimized or current_prompt
                else:
                    optimized_configs[agent_type] = current_prompt
            
            # æ›´æ–°æœ€åä¼˜åŒ–æ—¶é—´
            self.last_optimization = {
                "timestamp": datetime.now().isoformat(),
                "optimized_agents": list(optimized_configs.keys())
            }
            
        finally:
            self.is_running = False
        
        return optimized_configs
    
    async def _should_optimize(self, agent_type: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¼˜åŒ–"""
        # æ£€æŸ¥åé¦ˆæ•°é‡
        feedback_count = await self._get_feedback_count(agent_type)
        return feedback_count >= self.config["min_feedback_count"]
    
    async def _get_feedback_count(self, agent_type: str) -> int:
        """è·å–åé¦ˆæ•°é‡"""
        feedback_memories = await self.prompt_optimizer.memory_manager.search_memories(
            query="ç”¨æˆ·åé¦ˆ",
            namespace=f"feedback_{agent_type}",
            limit=100
        )
        return len(feedback_memories)
```

### APIé›†æˆ

#### æç¤ºè¯ä¼˜åŒ–APIè·¯ç”±

```python
# core/optimization/prompt_optimization_api.py
from fastapi import APIRouter, HTTPException, Depends
from typing import Dict, Any, List, Optional
from models.base_models import BaseResponse
from pydantic import BaseModel

router = APIRouter(prefix="/api/v1/optimization", tags=["æç¤ºè¯ä¼˜åŒ–"])

class FeedbackRequest(BaseModel):
    conversation_id: str
    satisfaction_score: float
    feedback_text: str = ""
    agent_type: str = "default"
    messages: List[Dict[str, Any]] = []

class OptimizationRequest(BaseModel):
    current_prompt: str
    min_feedback_count: int = 10

class MultiAgentOptimizationRequest(BaseModel):
    agent_prompts: Dict[str, str]

@router.post("/feedback")
async def submit_feedback(
    request: FeedbackRequest,
    feedback_collector: FeedbackCollector = Depends(get_feedback_collector)
):
    """æäº¤ç”¨æˆ·åé¦ˆ"""
    try:
        await feedback_collector.collect_user_feedback(
            conversation_id=request.conversation_id,
            messages=request.messages,
            satisfaction_score=request.satisfaction_score,
            feedback_text=request.feedback_text,
            agent_type=request.agent_type
        )
        return BaseResponse(message="åé¦ˆå·²æ”¶é›†")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/agents/{agent_type}/optimize")
async def optimize_agent_prompt(
    agent_type: str,
    request: OptimizationRequest,
    prompt_optimizer: PromptOptimizer = Depends(get_prompt_optimizer)
):
    """ä¼˜åŒ–å•ä¸ªæ™ºèƒ½ä½“æç¤ºè¯"""
    try:
        optimized_prompt = await prompt_optimizer.optimize_agent_prompt(
            agent_type=agent_type,
            current_prompt=request.current_prompt,
            min_feedback_count=request.min_feedback_count
        )
        
        if optimized_prompt:
            return {
                "status": "success",
                "optimized_prompt": optimized_prompt,
                "improvement_detected": True
            }
        else:
            return {
                "status": "skipped",
                "message": "åé¦ˆæ•°æ®ä¸è¶³æˆ–æ— éœ€ä¼˜åŒ–",
                "improvement_detected": False
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/multi-agent/optimize")
async def optimize_multi_agent_system(
    request: MultiAgentOptimizationRequest,
    prompt_optimizer: PromptOptimizer = Depends(get_prompt_optimizer)
):
    """ä¼˜åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ"""
    try:
        optimized_prompts = await prompt_optimizer.optimize_multi_agent_system(
            agent_prompts=request.agent_prompts
        )
        return {
            "status": "success",
            "optimized_prompts": optimized_prompts
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### æœ€ä½³å®è·µ

#### 1. åé¦ˆæ”¶é›†ç­–ç•¥
- **åŠæ—¶æ”¶é›†**ï¼šåœ¨æ¯æ¬¡å¯¹è¯ç»“æŸåæ”¶é›†åé¦ˆ
- **å¤šç»´åº¦è¯„ä¼°**ï¼šæ”¶é›†æ»¡æ„åº¦è¯„åˆ†ã€å…·ä½“å»ºè®®ã€æ”¹è¿›æ–¹å‘
- **ç”¨æˆ·å‹å¥½**ï¼šä½¿ç”¨ç®€å•çš„è¯„åˆ†ç³»ç»Ÿï¼ˆ1-5æ˜Ÿï¼‰å’Œå¯é€‰çš„æ–‡å­—åé¦ˆ

#### 2. ä¼˜åŒ–é¢‘ç‡æ§åˆ¶
- **å®šæœŸä¼˜åŒ–**ï¼šå»ºè®®æ¯å‘¨æ‰§è¡Œä¸€æ¬¡è‡ªåŠ¨ä¼˜åŒ–
- **æ•°æ®é—¨æ§›**ï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„åé¦ˆæ•°æ®ï¼ˆå»ºè®®â‰¥10æ¡ï¼‰
- **æ¸è¿›æ”¹è¿›**ï¼šé¿å…é¢‘ç¹çš„å¤§å¹…åº¦æç¤ºè¯å˜æ›´

#### 3. ç‰ˆæœ¬ç®¡ç†
- **è®°å½•å†å²**ï¼šä¿å­˜æ‰€æœ‰ä¼˜åŒ–å†å²å’Œæ•ˆæœå¯¹æ¯”
- **å›æ»šæœºåˆ¶**ï¼šæ”¯æŒå›é€€åˆ°ä¹‹å‰çš„æç¤ºè¯ç‰ˆæœ¬
- **A/Bæµ‹è¯•**ï¼šå¯¹æ¯”æ–°æ—§æç¤ºè¯çš„æ•ˆæœ

## æ™ºèƒ½ä½“ç±»å‹é›†æˆç¤ºä¾‹

### 1. è®°å¿†å¢å¼ºçš„ç›‘ç£æ™ºèƒ½ä½“

```python
# core/agents/supervisor_agent.py
import asyncio
from typing import Dict, Any, List
from langmem import create_manage_memory_tool, create_search_memory_tool
from core.memory.store_manager import memory_store_manager

class MemoryEnhancedSupervisorAgent:
    """å¸¦è®°å¿†åŠŸèƒ½çš„ç›‘ç£æ™ºèƒ½ä½“"""
    
    def __init__(self, agent_id: str = "supervisor"):
        self.agent_id = agent_id
        self.namespace = f"supervisor_{agent_id}"
        
        # è®°å¿†å·¥å…·
        self.manage_memory_tool = None
        self.search_memory_tool = None
        
    async def initialize(self):
        """åˆå§‹åŒ–è®°å¿†å·¥å…·"""
        await memory_store_manager.initialize()
        
        self.manage_memory_tool = create_manage_memory_tool(
            store=memory_store_manager.store,
            namespace=self.namespace
        )
        
        self.search_memory_tool = create_search_memory_tool(
            store=memory_store_manager.store,
            namespace=self.namespace
        )
    
    async def coordinate_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """åè°ƒä»»åŠ¡æ‰§è¡Œï¼Œåˆ©ç”¨è®°å¿†ä¼˜åŒ–å†³ç­–"""
        if not self.search_memory_tool:
            await self.initialize()
        
        # æœç´¢ç›¸å…³çš„å†å²ä»»åŠ¡è®°å¿†
        similar_tasks = await self.search_memory_tool.ainvoke({
            "query": f"ä»»åŠ¡ç±»å‹: {task.get('type', '')} ä»»åŠ¡æè¿°: {task.get('description', '')}",
            "limit": 3
        })
        
        # åŸºäºå†å²ç»éªŒåšå‡ºå†³ç­–
        coordination_result = await self._make_coordination_decision(task, similar_tasks)
        
        # å­˜å‚¨ä»»åŠ¡åè°ƒè®°å¿†
        await self.manage_memory_tool.ainvoke({
            "action": "store",
            "memory": {
                "content": f"ä»»åŠ¡åè°ƒ: {task['description']} -> åˆ†é…ç»™: {coordination_result['assigned_agents']}",
                "type": "procedural",
                "metadata": {
                    "task_id": task.get("id"),
                    "task_type": task.get("type"),
                    "assigned_agents": coordination_result["assigned_agents"],
                    "coordination_strategy": coordination_result["strategy"]
                }
            }
        })
        
        return coordination_result
    
    async def _make_coordination_decision(self, task: Dict[str, Any], 
                                        similar_tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŸºäºå†å²è®°å¿†åšå‡ºåè°ƒå†³ç­–"""
        # åˆ†æå†å²ä»»åŠ¡çš„æˆåŠŸæ¨¡å¼
        successful_patterns = []
        for memory in similar_tasks.get("memories", []):
            if memory.get("metadata", {}).get("success_rate", 0) > 0.8:
                successful_patterns.append(memory["metadata"])
        
        # åŸºäºæˆåŠŸæ¨¡å¼é€‰æ‹©æ™ºèƒ½ä½“
        if successful_patterns:
            # ä½¿ç”¨å†å²æˆåŠŸçš„æ™ºèƒ½ä½“ç»„åˆ
            assigned_agents = successful_patterns[0].get("assigned_agents", ["default_agent"])
            strategy = "å†å²æˆåŠŸæ¨¡å¼"
        else:
            # é»˜è®¤åˆ†é…ç­–ç•¥
            assigned_agents = self._default_assignment(task)
            strategy = "é»˜è®¤åˆ†é…"
        
        return {
            "assigned_agents": assigned_agents,
            "strategy": strategy,
            "confidence": 0.9 if successful_patterns else 0.6
        }
    
    def _default_assignment(self, task: Dict[str, Any]) -> List[str]:
        """é»˜è®¤ä»»åŠ¡åˆ†é…é€»è¾‘"""
        task_type = task.get("type", "general")
        
        assignment_map = {
            "research": ["research_agent", "web_search_agent"],
            "analysis": ["analysis_agent", "data_agent"],
            "writing": ["writing_agent", "review_agent"],
            "coding": ["coding_agent", "test_agent"]
        }
        
        return assignment_map.get(task_type, ["general_agent"])
```

### 2. è®°å¿†å¢å¼ºçš„RAGæ™ºèƒ½ä½“

```python
# core/agents/rag_agent.py
import asyncio
from typing import Dict, Any, List, Optional
from langmem import create_manage_memory_tool, create_search_memory_tool
from core.memory.store_manager import memory_store_manager

class MemoryEnhancedRAGAgent:
    """å¸¦è®°å¿†åŠŸèƒ½çš„RAGæ™ºèƒ½ä½“"""
    
    def __init__(self, agent_id: str = "rag_agent"):
        self.agent_id = agent_id
        self.namespace = f"rag_{agent_id}"
        
        # è®°å¿†å·¥å…·
        self.manage_memory_tool = None
        self.search_memory_tool = None
        
    async def initialize(self):
        """åˆå§‹åŒ–è®°å¿†å·¥å…·"""
        await memory_store_manager.initialize()
        
        self.manage_memory_tool = create_manage_memory_tool(
            store=memory_store_manager.store,
            namespace=self.namespace
        )
        
        self.search_memory_tool = create_search_memory_tool(
            store=memory_store_manager.store,
            namespace=self.namespace
        )
    
    async def enhanced_retrieval(self, query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """è®°å¿†å¢å¼ºçš„æ£€ç´¢"""
        if not self.search_memory_tool:
            await self.initialize()
        
        # 1. æœç´¢æŸ¥è¯¢æ¨¡å¼è®°å¿†
        query_patterns = await self.search_memory_tool.ainvoke({
            "query": f"æŸ¥è¯¢æ¨¡å¼: {query}",
            "limit": 3
        })
        
        # 2. ä¼˜åŒ–æŸ¥è¯¢
        optimized_query = await self._optimize_query(query, query_patterns)
        
        # 3. æ‰§è¡Œæ£€ç´¢ï¼ˆè¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„RAGæ£€ç´¢é€»è¾‘ï¼‰
        retrieval_results = await self._perform_retrieval(optimized_query)
        
        # 4. å­˜å‚¨æŸ¥è¯¢æ¨¡å¼è®°å¿†
        await self.manage_memory_tool.ainvoke({
            "action": "store",
            "memory": {
                "content": f"æŸ¥è¯¢: {query} -> ä¼˜åŒ–æŸ¥è¯¢: {optimized_query}",
                "type": "procedural",
                "metadata": {
                    "original_query": query,
                    "optimized_query": optimized_query,
                    "results_count": len(retrieval_results.get("documents", [])),
                    "context": context
                }
            }
        })
        
        return {
            "query": optimized_query,
            "documents": retrieval_results.get("documents", []),
            "optimization_applied": optimized_query != query
        }
    
    async def _optimize_query(self, query: str, query_patterns: Dict[str, Any]) -> str:
        """åŸºäºå†å²æ¨¡å¼ä¼˜åŒ–æŸ¥è¯¢"""
        patterns = query_patterns.get("memories", [])
        
        if not patterns:
            return query
        
        # åˆ†ææˆåŠŸçš„æŸ¥è¯¢æ¨¡å¼
        successful_patterns = [
            p for p in patterns 
            if p.get("metadata", {}).get("results_count", 0) > 0
        ]
        
        if successful_patterns:
            # åº”ç”¨æœ€æˆåŠŸçš„æŸ¥è¯¢ä¼˜åŒ–æ¨¡å¼
            best_pattern = max(
                successful_patterns,
                key=lambda x: x.get("metadata", {}).get("results_count", 0)
            )
            
            # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æŸ¥è¯¢ä¼˜åŒ–é€»è¾‘
            # ä¾‹å¦‚æ·»åŠ å…³é”®è¯ã€è°ƒæ•´æŸ¥è¯¢ç»“æ„ç­‰
            optimized = query + " " + best_pattern.get("metadata", {}).get("optimization_keywords", "")
            return optimized.strip()
        
        return query
    
    async def _perform_retrieval(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡Œå®é™…çš„æ£€ç´¢æ“ä½œ"""
        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„RAGæ£€ç´¢é€»è¾‘
        # ä¾‹å¦‚è°ƒç”¨å‘é‡æ•°æ®åº“ã€æœç´¢å¼•æ“ç­‰
        
        # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
        return {
            "documents": [
                {"content": f"æ£€ç´¢åˆ°çš„æ–‡æ¡£1 for: {query}", "score": 0.9},
                {"content": f"æ£€ç´¢åˆ°çš„æ–‡æ¡£2 for: {query}", "score": 0.8},
            ]
        }
    
    async def record_feedback(self, query: str, results: List[Dict[str, Any]], 
                            user_feedback: Dict[str, Any]):
        """è®°å½•ç”¨æˆ·åé¦ˆï¼Œç”¨äºæ”¹è¿›æ£€ç´¢"""
        if not self.manage_memory_tool:
            await self.initialize()
        
        await self.manage_memory_tool.ainvoke({
            "action": "store",
            "memory": {
                "content": f"ç”¨æˆ·åé¦ˆ: æŸ¥è¯¢'{query}' æ»¡æ„åº¦: {user_feedback.get('satisfaction', 'unknown')}",
                "type": "episodic",
                "metadata": {
                    "query": query,
                    "results_count": len(results),
                    "satisfaction": user_feedback.get("satisfaction"),
                    "helpful_docs": user_feedback.get("helpful_docs", []),
                    "suggestions": user_feedback.get("suggestions", "")
                }
            }
        })
```

## è®°å¿†ç®¡ç†APIå®ç°

### æ ¸å¿ƒè®°å¿†æ“ä½œ

```python
# core/memory/api.py
import asyncio
from typing import Dict, Any, List, Optional
from langmem import create_manage_memory_tool, create_search_memory_tool
from core.memory.store_manager import memory_store_manager

class MemoryAPI:
    """è®°å¿†ç®¡ç†APIå°è£…"""
    
    def __init__(self, namespace: str):
        self.namespace = namespace
        self.manage_tool = None
        self.search_tool = None
        
    async def initialize(self):
        """åˆå§‹åŒ–è®°å¿†å·¥å…·"""
        await memory_store_manager.initialize()
        
        self.manage_tool = create_manage_memory_tool(
            store=memory_store_manager.store,
            namespace=self.namespace
        )
        
        self.search_tool = create_search_memory_tool(
            store=memory_store_manager.store,
            namespace=self.namespace
        )
    
    async def store_memory(self, content: str, memory_type: str = "episodic", 
                          metadata: Optional[Dict[str, Any]] = None) -> bool:
        """å­˜å‚¨è®°å¿†"""
        if not self.manage_tool:
            await self.initialize()
        
        try:
            result = await self.manage_tool.ainvoke({
                "action": "store",
                "memory": {
                    "content": content,
                    "type": memory_type,
                    "metadata": metadata or {}
                }
            })
            return result.get("success", False)
        except Exception as e:
            print(f"å­˜å‚¨è®°å¿†å¤±è´¥: {e}")
            return False
    
    async def search_memories(self, query: str, limit: int = 5, 
                            memory_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """æœç´¢è®°å¿†"""
        if not self.search_tool:
            await self.initialize()
        
        try:
            search_params = {
                "query": query,
                "limit": limit
            }
            
            if memory_type:
                search_params["filter"] = {"type": memory_type}
            
            result = await self.search_tool.ainvoke(search_params)
            return result.get("memories", [])
        except Exception as e:
            print(f"æœç´¢è®°å¿†å¤±è´¥: {e}")
            return []
    
    async def update_memory(self, memory_id: str, updates: Dict[str, Any]) -> bool:
        """æ›´æ–°è®°å¿†"""
        if not self.manage_tool:
            await self.initialize()
        
        try:
            result = await self.manage_tool.ainvoke({
                "action": "update",
                "memory_id": memory_id,
                "updates": updates
            })
            return result.get("success", False)
        except Exception as e:
            print(f"æ›´æ–°è®°å¿†å¤±è´¥: {e}")
            return False
    
    async def delete_memory(self, memory_id: str) -> bool:
        """åˆ é™¤è®°å¿†"""
        if not self.manage_tool:
            await self.initialize()
        
        try:
            result = await self.manage_tool.ainvoke({
                "action": "delete",
                "memory_id": memory_id
            })
            return result.get("success", False)
        except Exception as e:
            print(f"åˆ é™¤è®°å¿†å¤±è´¥: {e}")
            return False

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    """è®°å¿†APIä½¿ç”¨ç¤ºä¾‹"""
    # åˆ›å»ºè®°å¿†APIå®ä¾‹
    memory_api = MemoryAPI("example_namespace")
    
    # å­˜å‚¨ä¸åŒç±»å‹çš„è®°å¿†
    await memory_api.store_memory(
        content="ç”¨æˆ·å–œæ¬¢æŠ€æœ¯ç±»æ–‡ç« ",
        memory_type="semantic",
        metadata={"category": "user_preference", "confidence": 0.9}
    )
    
    await memory_api.store_memory(
        content="2024-01-15: ç”¨æˆ·è¯¢é—®äº†Pythonå¼‚æ­¥ç¼–ç¨‹",
        memory_type="episodic",
        metadata={"timestamp": "2024-01-15", "topic": "python"}
    )
    
    await memory_api.store_memory(
        content="å¤„ç†æŠ€æœ¯é—®é¢˜çš„æ ‡å‡†æµç¨‹ï¼šåˆ†æ->æœç´¢->éªŒè¯->å›ç­”",
        memory_type="procedural",
        metadata={"process_type": "technical_support"}
    )
    
    # æœç´¢è®°å¿†
    tech_memories = await memory_api.search_memories(
        query="æŠ€æœ¯ Python",
        limit=3
    )
    
    print(f"æ‰¾åˆ° {len(tech_memories)} æ¡ç›¸å…³è®°å¿†")
    for memory in tech_memories:
        print(f"- {memory['content']}")

if __name__ == "__main__":
    asyncio.run(example_usage())
```

## API é›†æˆ

### 1. è®°å¿†ç®¡ç† API

```python
# app/api/memory.py
from fastapi import APIRouter, HTTPException, Depends
from app.core.memory.store_manager import memory_store_manager
from app.models.memory import MemoryManageRequest, MemorySearchRequest

router = APIRouter(prefix="/api/v1/memory", tags=["memory"])

@router.post("/manage")
async def manage_memory(request: MemoryManageRequest):
    """ç®¡ç†è®°å¿†"""
    try:
        namespace = memory_store_manager.get_namespace(
            request.agent_id, request.session_id
        )
        
        if request.memory_type:
            namespace = f"{namespace}_{request.memory_type}"
        
        manage_tool = MemoryToolsFactory.create_manage_memory_tool(namespace)
        result = await manage_tool.ainvoke({
            "action": request.action,
            "memory": request.memory_data
        })
        
        return {"status": "success", "result": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/search")
async def search_memory(request: MemorySearchRequest):
    """æœç´¢è®°å¿†"""
    try:
        namespace = memory_store_manager.get_namespace(
            request.agent_id, request.session_id
        )
        
        if request.memory_type:
            namespace = f"{namespace}_{request.memory_type}"
        
        search_tool = MemoryToolsFactory.create_search_memory_tool(namespace)
        results = await search_tool.ainvoke({
            "query": request.query,
            "limit": request.limit
        })
        
        return {"status": "success", "memories": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

## æœ€ä½³å®è·µ

### 1. å‘½åç©ºé—´è®¾è®¡
- ä½¿ç”¨å±‚æ¬¡åŒ–å‘½åç©ºé—´: `agent_{agent_id}_session_{session_id}_{memory_type}`
- ä¸ºä¸åŒè®°å¿†ç±»å‹ä½¿ç”¨ç‹¬ç«‹å‘½åç©ºé—´
- è€ƒè™‘å¤šç§Ÿæˆ·éš”ç¦»éœ€æ±‚

### 2. è®°å¿†ç”Ÿå‘½å‘¨æœŸç®¡ç†
- å®šæœŸæ¸…ç†è¿‡æœŸè®°å¿†
- å®æ–½è®°å¿†æ•´åˆç­–ç•¥
- å¤‡ä»½é‡è¦è®°å¿†æ•°æ®

### 3. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨ Redis ç¼“å­˜é¢‘ç¹è®¿é—®çš„è®°å¿†
- æ‰¹é‡å¤„ç†è®°å¿†æ“ä½œ
- å¼‚æ­¥å¤„ç†è®°å¿†æ›´æ–°

### 4. å®‰å…¨è€ƒè™‘
- åŠ å¯†æ•æ„Ÿè®°å¿†å†…å®¹
- å®æ–½è®¿é—®æ§åˆ¶
- å®¡è®¡è®°å¿†æ“ä½œæ—¥å¿—

## ç›‘æ§å’Œè°ƒè¯•

### 1. è®°å¿†ç³»ç»ŸæŒ‡æ ‡
- è®°å¿†å­˜å‚¨å¤§å°
- æœç´¢å“åº”æ—¶é—´
- è®°å¿†å‘½ä¸­ç‡
- æ•´åˆæ“ä½œé¢‘ç‡

### 2. è°ƒè¯•å·¥å…·
- è®°å¿†å†…å®¹æŸ¥çœ‹å™¨
- å‘½åç©ºé—´æµè§ˆå™¨
- æœç´¢ç»“æœåˆ†æå™¨

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **è®°å¿†æœç´¢æ— ç»“æœ**: æ£€æŸ¥å‘½åç©ºé—´é…ç½®å’ŒåµŒå…¥æ¨¡å‹
2. **å­˜å‚¨è¿æ¥å¤±è´¥**: éªŒè¯ PostgreSQL è¿æ¥å­—ç¬¦ä¸²
3. **è®°å¿†æ•´åˆå¤±è´¥**: æ£€æŸ¥å­˜å‚¨ç©ºé—´å’Œæƒé™
4. **æ€§èƒ½é—®é¢˜**: ä¼˜åŒ–ç´¢å¼•é…ç½®å’Œç¼“å­˜ç­–ç•¥

é€šè¿‡ä»¥ä¸Šé›†æˆæŒ‡å—ï¼Œå¯ä»¥åœ¨å¤šæ™ºèƒ½ä½“åä½œå¹³å°ä¸­å……åˆ†åˆ©ç”¨ LangMem çš„è®°å¿†ç®¡ç†èƒ½åŠ›ï¼Œæå‡æ™ºèƒ½ä½“çš„å­¦ä¹ å’Œé€‚åº”èƒ½åŠ›ã€‚