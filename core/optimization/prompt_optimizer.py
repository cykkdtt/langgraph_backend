"""
LangMem æç¤ºè¯ä¼˜åŒ–é›†æˆæ–¹æ¡ˆ

è¿™ä¸ªæ¨¡å—å±•ç¤ºäº†å¦‚ä½•åœ¨ç°æœ‰é¡¹ç›®ä¸­é›†æˆLangMemçš„æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½ï¼Œ
åŒ…æ‹¬ä¸ç°æœ‰æ™ºèƒ½ä½“ç³»ç»Ÿçš„é›†æˆã€åé¦ˆæ”¶é›†æœºåˆ¶å’Œè‡ªåŠ¨ä¼˜åŒ–æµç¨‹ã€‚
"""

from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
import asyncio
from pathlib import Path

# é¡¹ç›®ç°æœ‰æ¨¡å—
from core.memory.store_manager import MemoryStoreManager
from core.agents.base import BaseAgent
from models.chat_models import Message, ChatResponse

# LangMem æç¤ºè¯ä¼˜åŒ– (éœ€è¦å®‰è£…)
try:
    from langmem import create_prompt_optimizer, create_multi_prompt_optimizer
    LANGMEM_AVAILABLE = True
except ImportError:
    LANGMEM_AVAILABLE = False


class PromptOptimizer:
    """æç¤ºè¯ä¼˜åŒ–å™¨ - é›†æˆLangMemçš„æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½"""
    
    def __init__(self, memory_manager: MemoryStoreManager, model_name: str = "anthropic:claude-3-5-sonnet-latest"):
        self.memory_manager = memory_manager
        self.model_name = model_name
        self.feedback_namespace = "prompt_feedback"
        self.optimization_namespace = "prompt_optimization"
        self.initialized = False
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        if LANGMEM_AVAILABLE:
            self.single_optimizer = create_prompt_optimizer(
                model_name,
                kind="gradient",
                config={"max_reflection_steps": 2}
            )
            self.multi_optimizer = create_multi_prompt_optimizer(
                model_name,
                kind="gradient",
                config={"max_reflection_steps": 2}
            )
        else:
            self.single_optimizer = None
            self.multi_optimizer = None
    
    async def initialize(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        if not self.initialized:
            await self.memory_manager.initialize()
            self.initialized = True
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return {
            "status": "healthy" if LANGMEM_AVAILABLE else "limited",
            "langmem_available": LANGMEM_AVAILABLE,
            "initialized": self.initialized,
            "model_name": self.model_name
        }
    
    async def collect_feedback(self, 
                             conversation_id: str,
                             messages: List[Message],
                             feedback: Dict[str, Any]) -> None:
        """æ”¶é›†ç”¨æˆ·åé¦ˆç”¨äºæç¤ºè¯ä¼˜åŒ–"""
        
        feedback_data = {
            "conversation_id": conversation_id,
            "timestamp": datetime.now().isoformat(),
            "messages": [msg.dict() for msg in messages],
            "feedback": feedback,
            "agent_type": feedback.get("agent_type", "unknown")
        }
        
        # å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ
        await self.memory_manager.store_memory(
            content=json.dumps(feedback_data),
            memory_type="episodic",
            namespace=self.feedback_namespace,
            metadata={
                "conversation_id": conversation_id,
                "agent_type": feedback.get("agent_type"),
                "satisfaction_score": feedback.get("score", 0),
                "feedback_type": "user_feedback"
            }
        )
    
    async def optimize_agent_prompt(self, 
                                  agent_type: str,
                                  user_id: Optional[str] = None,
                                  strategy: str = "gradient",
                                  max_iterations: int = 5,
                                  context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ä¼˜åŒ–å•ä¸ªæ™ºèƒ½ä½“çš„æç¤ºè¯"""
        
        if not LANGMEM_AVAILABLE:
            raise Exception("LangMemæœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œæç¤ºè¯ä¼˜åŒ–")
        
        # è·å–å½“å‰æç¤ºè¯ï¼ˆè¿™é‡Œéœ€è¦ä»æ™ºèƒ½ä½“é…ç½®ä¸­è·å–ï¼‰
        current_prompt = context.get("current_prompt", f"ä½ æ˜¯ä¸€ä¸ª{agent_type}æ™ºèƒ½ä½“ã€‚")
        
        # è·å–è¯¥æ™ºèƒ½ä½“ç±»å‹çš„åé¦ˆæ•°æ®
        query_filter = {"agent_type": agent_type}
        if user_id:
            query_filter["user_id"] = user_id
            
        feedback_memories = await self.memory_manager.search_memories(
            query=f"agent_type:{agent_type}",
            namespace=self.feedback_namespace,
            limit=50
        )
        
        min_feedback_count = context.get("min_feedback_count", 10)
        if len(feedback_memories) < min_feedback_count:
            raise Exception(f"åé¦ˆæ•°æ®ä¸è¶³ ({len(feedback_memories)}/{min_feedback_count})")
        
        # è½¬æ¢ä¸ºä¼˜åŒ–å™¨éœ€è¦çš„æ ¼å¼
        trajectories = []
        for memory in feedback_memories:
            try:
                data = json.loads(memory.content)
                messages = data["messages"]
                feedback = data["feedback"]
                
                # æ„å»ºå¯¹è¯è½¨è¿¹
                trajectory = (messages, feedback)
                trajectories.append(trajectory)
                
            except (json.JSONDecodeError, KeyError) as e:
                continue
        
        if not trajectories:
            raise Exception("æ²¡æœ‰æœ‰æ•ˆçš„åé¦ˆæ•°æ®")
        
        try:
            # æ‰§è¡Œæç¤ºè¯ä¼˜åŒ–
            optimized_prompt = await self.single_optimizer.ainvoke({
                "trajectories": trajectories,
                "prompt": current_prompt
            })
            
            # è®¡ç®—æ”¹è¿›åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            improvement_score = len(trajectories) * 0.1  # ç®€åŒ–è®¡ç®—
            
            # ç”Ÿæˆä¼˜åŒ–ID
            optimization_id = f"opt_{agent_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # ä¿å­˜ä¼˜åŒ–ç»“æœ
            await self._save_optimization_result(
                agent_type, current_prompt, optimized_prompt, trajectories, optimization_id
            )
            
            return {
                "optimization_id": optimization_id,
                "original_prompt": current_prompt,
                "optimized_prompt": optimized_prompt,
                "improvement_score": improvement_score,
                "details": {
                    "strategy": strategy,
                    "feedback_count": len(trajectories),
                    "iterations": max_iterations,
                    "agent_type": agent_type,
                    "user_id": user_id
                }
            }
            
        except Exception as e:
            raise Exception(f"æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
    
    async def optimize_multi_agent_system(self, 
                                        agent_types: List[str],
                                        user_id: Optional[str] = None,
                                        strategy: str = "gradient",
                                        max_iterations: int = 5,
                                        context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ä¼˜åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ååŒæç¤ºè¯"""
        
        if not LANGMEM_AVAILABLE:
            raise Exception("LangMemæœªå®‰è£…ï¼Œæ— æ³•æ‰§è¡Œå¤šæ™ºèƒ½ä½“ä¼˜åŒ–")
        
        # æ„å»ºæ™ºèƒ½ä½“æç¤ºè¯åˆ—è¡¨
        agent_prompts = []
        for agent_type in agent_types:
            prompt = context.get(f"{agent_type}_prompt", f"ä½ æ˜¯ä¸€ä¸ª{agent_type}æ™ºèƒ½ä½“ã€‚")
            agent_prompts.append({"agent_type": agent_type, "prompt": prompt})
        
        # è·å–å¤šæ™ºèƒ½ä½“åä½œçš„åé¦ˆæ•°æ®
        feedback_memories = await self.memory_manager.search_memories(
            query="multi_agent OR collaboration OR team",
            namespace=self.feedback_namespace,
            limit=100
        )
        
        min_feedback_count = context.get("min_feedback_count", 20)
        if len(feedback_memories) < min_feedback_count:
            raise Exception(f"å¤šæ™ºèƒ½ä½“åé¦ˆæ•°æ®ä¸è¶³ ({len(feedback_memories)}/{min_feedback_count})")
        
        # æ„å»ºå›¢é˜Ÿå¯¹è¯è½¨è¿¹
        team_trajectories = []
        for memory in feedback_memories:
            try:
                data = json.loads(memory.content)
                if data.get("feedback", {}).get("type") == "multi_agent":
                    messages = data["messages"]
                    feedback = data["feedback"]
                    team_trajectories.append((messages, feedback))
            except (json.JSONDecodeError, KeyError):
                continue
        
        if not team_trajectories:
            raise Exception("æ²¡æœ‰æœ‰æ•ˆçš„å¤šæ™ºèƒ½ä½“åé¦ˆæ•°æ®")
        
        try:
            # æ‰§è¡Œå¤šæ™ºèƒ½ä½“ä¼˜åŒ–
            optimized_prompts = await self.multi_optimizer.ainvoke({
                "trajectories": team_trajectories,
                "prompts": agent_prompts
            })
            
            # è®¡ç®—æ•´ä½“æ”¹è¿›åˆ†æ•°
            overall_improvement = len(team_trajectories) * 0.15
            
            # ç”Ÿæˆä¼˜åŒ–ID
            optimization_id = f"multi_opt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # ä¿å­˜ä¼˜åŒ–ç»“æœ
            await self._save_multi_optimization_result(
                agent_prompts, optimized_prompts, team_trajectories, optimization_id
            )
            
            return {
                "optimization_id": optimization_id,
                "optimized_agents": optimized_prompts,
                "overall_improvement": overall_improvement,
                "details": {
                    "strategy": strategy,
                    "feedback_count": len(team_trajectories),
                    "iterations": max_iterations,
                    "agent_types": agent_types,
                    "user_id": user_id
                }
            }
            
        except Exception as e:
            raise Exception(f"å¤šæ™ºèƒ½ä½“ä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _save_optimization_result(self,
                                      agent_type: str,
                                      original_prompt: str,
                                      optimized_prompt: str,
                                      trajectories: List[Tuple],
                                      optimization_id: str) -> None:
        """ä¿å­˜å•æ™ºèƒ½ä½“ä¼˜åŒ–ç»“æœ"""
        
        result_data = {
            "optimization_id": optimization_id,
            "agent_type": agent_type,
            "timestamp": datetime.now().isoformat(),
            "original_prompt": original_prompt,
            "optimized_prompt": optimized_prompt,
            "feedback_count": len(trajectories),
            "optimization_type": "single_agent"
        }
        
        await self.memory_manager.store_memory(
            content=json.dumps(result_data),
            memory_type="procedural",
            namespace=self.optimization_namespace,
            metadata={
                "optimization_id": optimization_id,
                "agent_type": agent_type,
                "optimization_type": "single_agent",
                "feedback_count": len(trajectories)
            }
        )
    
    async def _save_multi_optimization_result(self,
                                            original_prompts: List[Dict[str, str]],
                                            optimized_prompts: List[Dict[str, str]],
                                            trajectories: List[Tuple],
                                            optimization_id: str) -> None:
        """ä¿å­˜å¤šæ™ºèƒ½ä½“ä¼˜åŒ–ç»“æœ"""
        
        result_data = {
            "optimization_id": optimization_id,
            "timestamp": datetime.now().isoformat(),
            "original_prompts": original_prompts,
            "optimized_prompts": optimized_prompts,
            "feedback_count": len(trajectories),
            "optimization_type": "multi_agent"
        }
        
        await self.memory_manager.store_memory(
            content=json.dumps(result_data),
            memory_type="procedural",
            namespace=self.optimization_namespace,
            metadata={
                "optimization_id": optimization_id,
                "optimization_type": "multi_agent",
                "agent_count": len(original_prompts),
                "feedback_count": len(trajectories)
            }
        )
    
    async def get_optimization_history(self, 
                                     filter_dict: Optional[Dict[str, Any]] = None,
                                     limit: int = 50,
                                     offset: int = 0) -> List[Dict[str, Any]]:
        """è·å–ä¼˜åŒ–å†å²è®°å½•"""
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        if filter_dict:
            query_parts = []
            for key, value in filter_dict.items():
                query_parts.append(f"{key}:{value}")
            query = " AND ".join(query_parts)
        else:
            query = "optimization"
        
        optimization_memories = await self.memory_manager.search_memories(
            query=query,
            namespace=self.optimization_namespace,
            limit=limit + offset  # è·å–æ›´å¤šæ•°æ®ç”¨äºåˆ†é¡µ
        )
        
        history = []
        for memory in optimization_memories:
            try:
                data = json.loads(memory.content)
                history.append(data)
            except json.JSONDecodeError:
                continue
        
        # æ’åºå¹¶åˆ†é¡µ
        sorted_history = sorted(history, key=lambda x: x["timestamp"], reverse=True)
        return sorted_history[offset:offset + limit]


class EnhancedChatResponse(ChatResponse):
    """å¢å¼ºçš„èŠå¤©å“åº”ï¼ŒåŒ…å«åé¦ˆæ”¶é›†åŠŸèƒ½"""
    
    feedback_collected: bool = False
    conversation_id: str = ""
    agent_type: str = ""


class FeedbackCollector:
    """åé¦ˆæ”¶é›†å™¨ - é›†æˆåˆ°ç°æœ‰APIä¸­"""
    
    def __init__(self, memory_manager: MemoryStoreManager):
        self.memory_manager = memory_manager
        self.feedback_namespace = "prompt_feedback"
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        return {
            "status": "healthy",
            "namespace": self.feedback_namespace
        }
    
    async def collect_feedback(self,
                             agent_type: str,
                             user_id: str,
                             session_id: str,
                             satisfaction_score: int,
                             feedback_text: Optional[str] = None,
                             improvement_suggestions: List[str] = None,
                             context: Dict[str, Any] = None) -> str:
        """æ”¶é›†ç”¨æˆ·åé¦ˆ"""
        
        feedback_id = f"feedback_{agent_type}_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        feedback_data = {
            "feedback_id": feedback_id,
            "agent_type": agent_type,
            "user_id": user_id,
            "session_id": session_id,
            "satisfaction_score": satisfaction_score,
            "feedback_text": feedback_text,
            "improvement_suggestions": improvement_suggestions or [],
            "context": context or {},
            "timestamp": datetime.now().isoformat(),
            "type": "user_feedback"
        }
        
        # å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ
        await self.memory_manager.store_memory(
            content=json.dumps(feedback_data),
            memory_type="episodic",
            namespace=self.feedback_namespace,
            metadata={
                "feedback_id": feedback_id,
                "agent_type": agent_type,
                "user_id": user_id,
                "session_id": session_id,
                "satisfaction_score": satisfaction_score,
                "feedback_type": "user_feedback"
            }
        )
        
        return feedback_id
    
    async def get_feedback_stats(self,
                               agent_type: str,
                               user_id: Optional[str] = None,
                               days: int = 30) -> Dict[str, Any]:
        """è·å–åé¦ˆç»Ÿè®¡"""
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = f"agent_type:{agent_type}"
        if user_id:
            query += f" AND user_id:{user_id}"
        
        # è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„åé¦ˆ
        feedback_memories = await self.memory_manager.search_memories(
            query=query,
            namespace=self.feedback_namespace,
            limit=1000  # è·å–è¶³å¤Ÿå¤šçš„æ•°æ®ç”¨äºç»Ÿè®¡
        )
        
        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_feedback = []
        
        for memory in feedback_memories:
            try:
                data = json.loads(memory.content)
                feedback_time = datetime.fromisoformat(data["timestamp"])
                if feedback_time >= cutoff_date:
                    recent_feedback.append(data)
            except (json.JSONDecodeError, KeyError, ValueError):
                continue
        
        if not recent_feedback:
            return {
                "total_count": 0,
                "average_satisfaction": 0,
                "satisfaction_distribution": {},
                "common_suggestions": []
            }
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        satisfaction_scores = [f["satisfaction_score"] for f in recent_feedback]
        average_satisfaction = sum(satisfaction_scores) / len(satisfaction_scores)
        
        # æ»¡æ„åº¦åˆ†å¸ƒ
        satisfaction_distribution = {}
        for score in satisfaction_scores:
            satisfaction_distribution[score] = satisfaction_distribution.get(score, 0) + 1
        
        # å¸¸è§å»ºè®®
        all_suggestions = []
        for f in recent_feedback:
            all_suggestions.extend(f.get("improvement_suggestions", []))
        
        suggestion_counts = {}
        for suggestion in all_suggestions:
            suggestion_counts[suggestion] = suggestion_counts.get(suggestion, 0) + 1
        
        common_suggestions = sorted(suggestion_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            "total_count": len(recent_feedback),
            "average_satisfaction": round(average_satisfaction, 2),
            "satisfaction_distribution": satisfaction_distribution,
            "common_suggestions": [{"suggestion": s[0], "count": s[1]} for s in common_suggestions]
        }
    
    async def collect_user_feedback(self,
                                  conversation_id: str,
                                  messages: List[Message],
                                  satisfaction_score: float,
                                  feedback_text: str = "",
                                  agent_type: str = "general") -> None:
        """æ”¶é›†ç”¨æˆ·æ»¡æ„åº¦åé¦ˆï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        
        feedback = {
            "score": satisfaction_score,
            "text": feedback_text,
            "agent_type": agent_type,
            "type": "satisfaction",
            "timestamp": datetime.now().isoformat()
        }
        
        await self.collect_feedback_legacy(
            conversation_id, messages, feedback
        )
    
    async def collect_improvement_suggestion(self,
                                           conversation_id: str,
                                           messages: List[Message],
                                           suggestion: str,
                                           agent_type: str = "general") -> None:
        """æ”¶é›†æ”¹è¿›å»ºè®®ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        
        feedback = {
            "suggestion": suggestion,
            "agent_type": agent_type,
            "type": "improvement",
            "timestamp": datetime.now().isoformat()
        }
        
        await self.collect_feedback_legacy(
            conversation_id, messages, feedback
        )
    
    async def collect_feedback_legacy(self, 
                                    conversation_id: str,
                                    messages: List[Message],
                                    feedback: Dict[str, Any]) -> None:
        """æ”¶é›†ç”¨æˆ·åé¦ˆç”¨äºæç¤ºè¯ä¼˜åŒ–ï¼ˆæ—§ç‰ˆæœ¬å…¼å®¹ï¼‰"""
        
        feedback_data = {
            "conversation_id": conversation_id,
            "timestamp": datetime.now().isoformat(),
            "messages": [msg.dict() for msg in messages],
            "feedback": feedback,
            "agent_type": feedback.get("agent_type", "unknown")
        }
        
        # å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ
        await self.memory_manager.store_memory(
            content=json.dumps(feedback_data),
            memory_type="episodic",
            namespace=self.feedback_namespace,
            metadata={
                "conversation_id": conversation_id,
                "agent_type": feedback.get("agent_type"),
                "satisfaction_score": feedback.get("score", 0),
                "feedback_type": "user_feedback"
            }
        )


class AutoOptimizationScheduler:
    """è‡ªåŠ¨ä¼˜åŒ–è°ƒåº¦å™¨ - å®šæœŸæ‰§è¡Œæç¤ºè¯ä¼˜åŒ–"""
    
    def __init__(self, prompt_optimizer: PromptOptimizer, feedback_collector: FeedbackCollector):
        self.prompt_optimizer = prompt_optimizer
        self.feedback_collector = feedback_collector
        self.optimization_interval = timedelta(days=7)  # æ¯å‘¨ä¼˜åŒ–ä¸€æ¬¡
        self.last_optimization = {}
        self.is_running = False
        self.optimization_task = None
        self.config = {
            "enabled": False,
            "interval_hours": 24,
            "min_feedback_count": 10,
            "optimization_strategy": "gradient"
        }
    
    async def get_status(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        return {
            "is_running": self.is_running,
            "config": self.config,
            "last_optimization": {
                agent_type: time.isoformat() 
                for agent_type, time in self.last_optimization.items()
            }
        }
    
    async def start_auto_optimization(self,
                                    interval_hours: int = 24,
                                    min_feedback_count: int = 10,
                                    optimization_strategy: str = "gradient"):
        """å¯åŠ¨è‡ªåŠ¨ä¼˜åŒ–"""
        self.config.update({
            "enabled": True,
            "interval_hours": interval_hours,
            "min_feedback_count": min_feedback_count,
            "optimization_strategy": optimization_strategy
        })
        
        self.optimization_interval = timedelta(hours=interval_hours)
        
        if not self.is_running:
            self.is_running = True
            self.optimization_task = asyncio.create_task(self._optimization_loop())
    
    async def stop_auto_optimization(self):
        """åœæ­¢è‡ªåŠ¨ä¼˜åŒ–"""
        self.config["enabled"] = False
        self.is_running = False
        
        if self.optimization_task:
            self.optimization_task.cancel()
            try:
                await self.optimization_task
            except asyncio.CancelledError:
                pass
            self.optimization_task = None
    
    async def _optimization_loop(self):
        """è‡ªåŠ¨ä¼˜åŒ–å¾ªç¯"""
        while self.is_running:
            try:
                await self.run_optimization_cycle()
                await asyncio.sleep(self.optimization_interval.total_seconds())
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"è‡ªåŠ¨ä¼˜åŒ–å¾ªç¯å‡ºé”™: {e}")
                await asyncio.sleep(3600)  # å‡ºé”™æ—¶ç­‰å¾…1å°æ—¶åé‡è¯•
    
    async def run_optimization_cycle(self):
        """è¿è¡Œä¸€æ¬¡ä¼˜åŒ–å‘¨æœŸ"""
        if not self.config["enabled"]:
            return
        
        # è·å–éœ€è¦ä¼˜åŒ–çš„æ™ºèƒ½ä½“ç±»å‹
        agent_types = ["supervisor", "researcher", "writer", "reviewer"]  # å¯é…ç½®
        
        for agent_type in agent_types:
            try:
                if await self.should_optimize(agent_type):
                    await self._optimize_agent(agent_type)
            except Exception as e:
                print(f"ä¼˜åŒ–æ™ºèƒ½ä½“ {agent_type} å¤±è´¥: {e}")
    
    async def should_optimize(self, agent_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–"""
        
        last_time = self.last_optimization.get(agent_type)
        if not last_time:
            return True
        
        time_since_last = datetime.now() - last_time
        return time_since_last > self.optimization_interval
    
    async def _optimize_agent(self, agent_type: str):
        """ä¼˜åŒ–å•ä¸ªæ™ºèƒ½ä½“"""
        
        # æ£€æŸ¥åé¦ˆæ•°é‡æ˜¯å¦è¶³å¤Ÿ
        stats = await self.feedback_collector.get_feedback_stats(
            agent_type=agent_type,
            days=self.optimization_interval.days
        )
        
        if stats["total_count"] < self.config["min_feedback_count"]:
            print(f"æ™ºèƒ½ä½“ {agent_type} åé¦ˆæ•°é‡ä¸è¶³ï¼Œè·³è¿‡ä¼˜åŒ–")
            return
        
        try:
            # æ‰§è¡Œä¼˜åŒ–
            result = await self.prompt_optimizer.optimize_agent_prompt(
                agent_type=agent_type,
                strategy=self.config["optimization_strategy"],
                context={
                    "min_feedback_count": self.config["min_feedback_count"],
                    "current_prompt": f"ä½ æ˜¯ä¸€ä¸ª{agent_type}æ™ºèƒ½ä½“ã€‚"  # è¿™é‡Œåº”è¯¥ä»é…ç½®ä¸­è·å–
                }
            )
            
            self.last_optimization[agent_type] = datetime.now()
            print(f"æ™ºèƒ½ä½“ {agent_type} ä¼˜åŒ–å®Œæˆ: {result['optimization_id']}")
            
        except Exception as e:
            print(f"æ™ºèƒ½ä½“ {agent_type} ä¼˜åŒ–å¤±è´¥: {e}")
    
    async def auto_optimize_agent(self, agent_type: str, current_prompt: str) -> Optional[str]:
        """è‡ªåŠ¨ä¼˜åŒ–æ™ºèƒ½ä½“æç¤ºè¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        
        if not await self.should_optimize(agent_type):
            return None
        
        print(f"ğŸ”„ å¼€å§‹è‡ªåŠ¨ä¼˜åŒ– {agent_type} æ™ºèƒ½ä½“...")
        
        try:
            result = await self.prompt_optimizer.optimize_agent_prompt(
                agent_type=agent_type,
                context={"current_prompt": current_prompt}
            )
            
            if result:
                self.last_optimization[agent_type] = datetime.now()
                print(f"âœ… {agent_type} æ™ºèƒ½ä½“ä¼˜åŒ–å®Œæˆ")
                return result["optimized_prompt"]
            else:
                print(f"âš ï¸ {agent_type} æ™ºèƒ½ä½“ä¼˜åŒ–è·³è¿‡")
                return None
                
        except Exception as e:
            print(f"âŒ {agent_type} æ™ºèƒ½ä½“ä¼˜åŒ–å¤±è´¥: {e}")
            return None
    
    async def run_optimization_cycle_legacy(self, agent_configs: Dict[str, str]) -> Dict[str, str]:
        """è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–å‘¨æœŸï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        
        optimized_configs = {}
        
        for agent_type, current_prompt in agent_configs.items():
            optimized_prompt = await self.auto_optimize_agent(agent_type, current_prompt)
            optimized_configs[agent_type] = optimized_prompt or current_prompt
        
        return optimized_configs


# ä½¿ç”¨ç¤ºä¾‹
async def demo_integration():
    """æ¼”ç¤ºé›†æˆä½¿ç”¨"""
    
    # åˆå§‹åŒ–ç»„ä»¶
    memory_manager = MemoryStoreManager()
    await memory_manager.initialize()
    
    prompt_optimizer = PromptOptimizer(memory_manager)
    feedback_collector = FeedbackCollector(prompt_optimizer)
    auto_scheduler = AutoOptimizationScheduler(prompt_optimizer)
    
    # æ¨¡æ‹Ÿæ”¶é›†åé¦ˆ
    messages = [
        Message(role="user", content="è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ "),
        Message(role="assistant", content="æœºå™¨å­¦ä¹ æ˜¯...")
    ]
    
    await feedback_collector.collect_user_feedback(
        conversation_id="conv_123",
        messages=messages,
        satisfaction_score=0.8,
        feedback_text="å›ç­”å¾ˆå¥½ï¼Œä½†å¸Œæœ›æœ‰æ›´å¤šä¾‹å­",
        agent_type="technical_assistant"
    )
    
    # æ¨¡æ‹Ÿè‡ªåŠ¨ä¼˜åŒ–
    agent_configs = {
        "technical_assistant": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£æŠ€æœ¯æ¦‚å¿µã€‚",
        "creative_writer": "ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å†™ä½œåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·åˆ›ä½œå†…å®¹ã€‚"
    }
    
    optimized_configs = await auto_scheduler.run_optimization_cycle(agent_configs)
    
    print("ğŸ‰ é›†æˆæ¼”ç¤ºå®Œæˆï¼")
    print(f"ä¼˜åŒ–ç»“æœ: {len(optimized_configs)} ä¸ªæ™ºèƒ½ä½“é…ç½®å·²æ›´æ–°")


if __name__ == "__main__":
    asyncio.run(demo_integration())