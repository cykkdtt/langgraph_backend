#!/usr/bin/env python3
"""
é«˜çº§æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º - å¤šæ™ºèƒ½ä½“åä½œåœºæ™¯

æ¼”ç¤ºåœ¨å¤æ‚å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å¦‚ä½•ä½¿ç”¨æ—¶é—´æ—…è¡ŒåŠŸèƒ½è¿›è¡Œï¼š
1. åä½œå†³ç­–çš„å›æ»šå’Œé‡è¯•
2. ä¸åŒç­–ç•¥çš„åˆ†æ”¯æµ‹è¯•
3. é”™è¯¯æ¢å¤å’ŒçŠ¶æ€ä¿®å¤
4. æ€§èƒ½ä¼˜åŒ–å’Œè·¯å¾„åˆ†æ

åŸºäºLangGraphå®˜æ–¹æ—¶é—´æ—…è¡ŒåŠŸèƒ½å®ç°ã€‚
"""

import asyncio
import uuid
from typing import TypedDict, Optional, List, Dict, Any, Literal
from datetime import datetime
from typing_extensions import NotRequired

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langchain.chat_models import init_chat_model

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from core.time_travel import (
    TimeTravelManager, TimeTravelConfig,
    SnapshotType, CheckpointType, RollbackStrategy
)


class MultiAgentState(TypedDict):
    """å¤šæ™ºèƒ½ä½“åä½œçŠ¶æ€"""
    task: str
    current_agent: str
    research_data: NotRequired[Dict[str, Any]]
    analysis_result: NotRequired[Dict[str, Any]]
    chart_data: NotRequired[Dict[str, Any]]
    final_report: NotRequired[str]
    decision_history: NotRequired[List[Dict[str, Any]]]
    error_count: NotRequired[int]
    strategy: NotRequired[str]
    quality_score: NotRequired[float]


class AdvancedTimeTravelDemo:
    """é«˜çº§æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º"""
    
    def __init__(self):
        # åˆå§‹åŒ–LLM
        self.llm = init_chat_model(
            "openai:gpt-4o-mini",
            temperature=0.3,
        )
        
        # åˆå§‹åŒ–æ£€æŸ¥ç‚¹ä¿å­˜å™¨
        self.checkpointer = InMemorySaver()
        
        # åˆå§‹åŒ–æ—¶é—´æ—…è¡Œç®¡ç†å™¨
        self.time_travel_config = TimeTravelConfig(
            auto_snapshot=True,
            snapshot_interval=1,
            auto_checkpoint=True,
            checkpoint_on_error=True,
            checkpoint_on_milestone=True,
            enable_branching=True
        )
        self.time_travel_manager = TimeTravelManager(self.time_travel_config)
        
        # æ„å»ºå¤šæ™ºèƒ½ä½“åä½œå›¾
        self.graph = self._build_multi_agent_graph()
        
    def _build_multi_agent_graph(self) -> StateGraph:
        """æ„å»ºå¤šæ™ºèƒ½ä½“åä½œå›¾"""
        workflow = StateGraph(MultiAgentState)
        
        # æ·»åŠ æ™ºèƒ½ä½“èŠ‚ç‚¹
        workflow.add_node("supervisor", self._supervisor_agent)
        workflow.add_node("researcher", self._research_agent)
        workflow.add_node("analyst", self._analysis_agent)
        workflow.add_node("chart_maker", self._chart_agent)
        workflow.add_node("reporter", self._report_agent)
        workflow.add_node("quality_checker", self._quality_checker)
        workflow.add_node("error_handler", self._error_handler)
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_edge(START, "supervisor")
        workflow.add_conditional_edges(
            "supervisor",
            self._route_next_agent,
            {
                "research": "researcher",
                "analysis": "analyst", 
                "chart": "chart_maker",
                "report": "reporter",
                "quality": "quality_checker",
                "error": "error_handler",
                "end": END
            }
        )
        
        # æ‰€æœ‰æ™ºèƒ½ä½“å®Œæˆåå›åˆ°supervisor
        for agent in ["researcher", "analyst", "chart_maker", "reporter"]:
            workflow.add_edge(agent, "supervisor")
        
        workflow.add_edge("quality_checker", "supervisor")
        workflow.add_edge("error_handler", "supervisor")
        
        return workflow.compile(checkpointer=self.checkpointer)
    
    def _supervisor_agent(self, state: MultiAgentState) -> MultiAgentState:
        """ç›‘ç£æ™ºèƒ½ä½“ - åè°ƒä»»åŠ¡åˆ†é…"""
        print(f"ğŸ¯ ç›‘ç£æ™ºèƒ½ä½“: å½“å‰ä»»åŠ¡ - {state['task']}")
        
        # è®°å½•å†³ç­–å†å²
        decision_history = state.get("decision_history", [])
        
        # æ ¹æ®å½“å‰çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥
        if not state.get("research_data"):
            next_agent = "research"
            decision = "éœ€è¦è¿›è¡Œç ”ç©¶æ”¶é›†æ•°æ®"
        elif not state.get("analysis_result"):
            next_agent = "analysis"
            decision = "éœ€è¦åˆ†æç ”ç©¶æ•°æ®"
        elif not state.get("chart_data"):
            next_agent = "chart"
            decision = "éœ€è¦åˆ›å»ºå›¾è¡¨å¯è§†åŒ–"
        elif not state.get("final_report"):
            next_agent = "report"
            decision = "éœ€è¦ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"
        elif not state.get("quality_score"):
            next_agent = "quality"
            decision = "éœ€è¦è´¨é‡æ£€æŸ¥"
        else:
            next_agent = "end"
            decision = "ä»»åŠ¡å®Œæˆ"
        
        # æ£€æŸ¥é”™è¯¯è®¡æ•°
        error_count = state.get("error_count", 0)
        if error_count > 2:
            next_agent = "error"
            decision = "é”™è¯¯è¿‡å¤šï¼Œéœ€è¦é”™è¯¯å¤„ç†"
        
        decision_history.append({
            "timestamp": datetime.now().isoformat(),
            "agent": "supervisor",
            "decision": decision,
            "next_agent": next_agent,
            "state_summary": self._get_state_summary(state)
        })
        
        print(f"   å†³ç­–: {decision} -> {next_agent}")
        
        return {
            **state,
            "current_agent": next_agent,
            "decision_history": decision_history
        }
    
    def _research_agent(self, state: MultiAgentState) -> MultiAgentState:
        """ç ”ç©¶æ™ºèƒ½ä½“ - æ”¶é›†å’Œæ•´ç†æ•°æ®"""
        print("ğŸ” ç ”ç©¶æ™ºèƒ½ä½“: æ”¶é›†æ•°æ®...")
        
        # æ¨¡æ‹Ÿç ”ç©¶è¿‡ç¨‹
        strategy = state.get("strategy", "standard")
        
        if strategy == "deep":
            # æ·±åº¦ç ”ç©¶ç­–ç•¥
            research_data = {
                "sources": ["å­¦æœ¯è®ºæ–‡", "è¡Œä¸šæŠ¥å‘Š", "ä¸“å®¶è®¿è°ˆ", "å¸‚åœºè°ƒç ”"],
                "data_points": 150,
                "confidence": 0.9,
                "methodology": "æ·±åº¦åˆ†ææ³•"
            }
        elif strategy == "fast":
            # å¿«é€Ÿç ”ç©¶ç­–ç•¥
            research_data = {
                "sources": ["ç½‘ç»œæœç´¢", "æ–°é—»æŠ¥é“"],
                "data_points": 50,
                "confidence": 0.6,
                "methodology": "å¿«é€Ÿæ‰«ææ³•"
            }
        else:
            # æ ‡å‡†ç ”ç©¶ç­–ç•¥
            research_data = {
                "sources": ["å®˜æ–¹æ•°æ®", "è¡Œä¸šæŠ¥å‘Š", "æ–°é—»åˆ†æ"],
                "data_points": 100,
                "confidence": 0.8,
                "methodology": "æ ‡å‡†åˆ†ææ³•"
            }
        
        # æ¨¡æ‹Ÿå¯èƒ½çš„é”™è¯¯
        import random
        if random.random() < 0.2:  # 20%æ¦‚ç‡å‡ºé”™
            error_count = state.get("error_count", 0) + 1
            print(f"   âŒ ç ”ç©¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ (é”™è¯¯è®¡æ•°: {error_count})")
            return {
                **state,
                "error_count": error_count,
                "current_agent": "supervisor"
            }
        
        print(f"   âœ… ç ”ç©¶å®Œæˆ: {research_data['methodology']}, ç½®ä¿¡åº¦: {research_data['confidence']}")
        
        return {
            **state,
            "research_data": research_data,
            "current_agent": "supervisor"
        }
    
    def _analysis_agent(self, state: MultiAgentState) -> MultiAgentState:
        """åˆ†ææ™ºèƒ½ä½“ - åˆ†ææ•°æ®å¹¶å¾—å‡ºç»“è®º"""
        print("ğŸ“Š åˆ†ææ™ºèƒ½ä½“: åˆ†ææ•°æ®...")
        
        research_data = state.get("research_data", {})
        if not research_data:
            error_count = state.get("error_count", 0) + 1
            print("   âŒ ç¼ºå°‘ç ”ç©¶æ•°æ®ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return {
                **state,
                "error_count": error_count,
                "current_agent": "supervisor"
            }
        
        # åŸºäºç ”ç©¶æ•°æ®è¿›è¡Œåˆ†æ
        confidence = research_data.get("confidence", 0.5)
        data_points = research_data.get("data_points", 0)
        
        analysis_result = {
            "trends": ["ä¸Šå‡è¶‹åŠ¿", "å­£èŠ‚æ€§æ³¢åŠ¨", "å¸‚åœºæˆç†Ÿ"],
            "insights": [
                "å¸‚åœºéœ€æ±‚æŒç»­å¢é•¿",
                "ç«äº‰æ ¼å±€ç›¸å¯¹ç¨³å®š",
                "æŠ€æœ¯åˆ›æ–°æ˜¯å…³é”®é©±åŠ¨åŠ›"
            ],
            "recommendations": [
                "åŠ å¤§ç ”å‘æŠ•å…¥",
                "æ‰©å±•å¸‚åœºä»½é¢",
                "ä¼˜åŒ–äº§å“ç»“æ„"
            ],
            "confidence_score": min(confidence + 0.1, 1.0),
            "data_quality": "é«˜" if data_points > 100 else "ä¸­" if data_points > 50 else "ä½"
        }
        
        print(f"   âœ… åˆ†æå®Œæˆ: ç½®ä¿¡åº¦ {analysis_result['confidence_score']:.2f}")
        
        return {
            **state,
            "analysis_result": analysis_result,
            "current_agent": "supervisor"
        }
    
    def _chart_agent(self, state: MultiAgentState) -> MultiAgentState:
        """å›¾è¡¨æ™ºèƒ½ä½“ - åˆ›å»ºæ•°æ®å¯è§†åŒ–"""
        print("ğŸ“ˆ å›¾è¡¨æ™ºèƒ½ä½“: åˆ›å»ºå¯è§†åŒ–...")
        
        analysis_result = state.get("analysis_result", {})
        if not analysis_result:
            error_count = state.get("error_count", 0) + 1
            print("   âŒ ç¼ºå°‘åˆ†æç»“æœï¼Œæ— æ³•åˆ›å»ºå›¾è¡¨")
            return {
                **state,
                "error_count": error_count,
                "current_agent": "supervisor"
            }
        
        chart_data = {
            "chart_types": ["è¶‹åŠ¿å›¾", "é¥¼å›¾", "æŸ±çŠ¶å›¾"],
            "visualizations": [
                {"type": "line", "title": "å¸‚åœºè¶‹åŠ¿", "data_points": 12},
                {"type": "pie", "title": "å¸‚åœºä»½é¢", "segments": 5},
                {"type": "bar", "title": "ç«äº‰åˆ†æ", "categories": 8}
            ],
            "quality": "é«˜æ¸…",
            "format": "SVG",
            "interactive": True
        }
        
        print(f"   âœ… å›¾è¡¨åˆ›å»ºå®Œæˆ: {len(chart_data['visualizations'])} ä¸ªå¯è§†åŒ–")
        
        return {
            **state,
            "chart_data": chart_data,
            "current_agent": "supervisor"
        }
    
    def _report_agent(self, state: MultiAgentState) -> MultiAgentState:
        """æŠ¥å‘Šæ™ºèƒ½ä½“ - ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        print("ğŸ“ æŠ¥å‘Šæ™ºèƒ½ä½“: ç”ŸæˆæŠ¥å‘Š...")
        
        # æ£€æŸ¥æ‰€éœ€æ•°æ®
        required_data = ["research_data", "analysis_result", "chart_data"]
        missing_data = [key for key in required_data if not state.get(key)]
        
        if missing_data:
            error_count = state.get("error_count", 0) + 1
            print(f"   âŒ ç¼ºå°‘å¿…è¦æ•°æ®: {missing_data}")
            return {
                **state,
                "error_count": error_count,
                "current_agent": "supervisor"
            }
        
        # ç”ŸæˆæŠ¥å‘Š
        research_data = state["research_data"]
        analysis_result = state["analysis_result"]
        chart_data = state["chart_data"]
        
        final_report = f"""
        # å¸‚åœºåˆ†ææŠ¥å‘Š
        
        ## ç ”ç©¶æ–¹æ³•
        - æ•°æ®æ¥æº: {', '.join(research_data['sources'])}
        - æ•°æ®ç‚¹æ•°: {research_data['data_points']}
        - ç½®ä¿¡åº¦: {research_data['confidence']:.2f}
        
        ## ä¸»è¦å‘ç°
        {chr(10).join(f"- {insight}" for insight in analysis_result['insights'])}
        
        ## å»ºè®®
        {chr(10).join(f"- {rec}" for rec in analysis_result['recommendations'])}
        
        ## å¯è§†åŒ–
        åŒ…å« {len(chart_data['visualizations'])} ä¸ªå›¾è¡¨å’Œå¯è§†åŒ–
        
        æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """
        
        print("   âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        return {
            **state,
            "final_report": final_report.strip(),
            "current_agent": "supervisor"
        }
    
    def _quality_checker(self, state: MultiAgentState) -> MultiAgentState:
        """è´¨é‡æ£€æŸ¥æ™ºèƒ½ä½“ - è¯„ä¼°è¾“å‡ºè´¨é‡"""
        print("â­ è´¨é‡æ£€æŸ¥æ™ºèƒ½ä½“: è¯„ä¼°è´¨é‡...")
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        score = 0.0
        factors = []
        
        # æ£€æŸ¥ç ”ç©¶æ•°æ®è´¨é‡
        research_data = state.get("research_data", {})
        if research_data:
            confidence = research_data.get("confidence", 0)
            data_points = research_data.get("data_points", 0)
            research_score = (confidence * 0.7 + min(data_points / 100, 1.0) * 0.3)
            score += research_score * 0.3
            factors.append(f"ç ”ç©¶è´¨é‡: {research_score:.2f}")
        
        # æ£€æŸ¥åˆ†æç»“æœè´¨é‡
        analysis_result = state.get("analysis_result", {})
        if analysis_result:
            analysis_score = analysis_result.get("confidence_score", 0)
            score += analysis_score * 0.4
            factors.append(f"åˆ†æè´¨é‡: {analysis_score:.2f}")
        
        # æ£€æŸ¥å¯è§†åŒ–è´¨é‡
        chart_data = state.get("chart_data", {})
        if chart_data:
            chart_score = min(len(chart_data.get("visualizations", [])) / 3, 1.0)
            score += chart_score * 0.2
            factors.append(f"å¯è§†åŒ–è´¨é‡: {chart_score:.2f}")
        
        # æ£€æŸ¥æŠ¥å‘Šå®Œæ•´æ€§
        final_report = state.get("final_report", "")
        if final_report:
            report_score = min(len(final_report) / 500, 1.0)
            score += report_score * 0.1
            factors.append(f"æŠ¥å‘Šå®Œæ•´æ€§: {report_score:.2f}")
        
        print(f"   ğŸ“Š è´¨é‡è¯„ä¼°: {score:.2f}/1.0")
        for factor in factors:
            print(f"      - {factor}")
        
        return {
            **state,
            "quality_score": score,
            "current_agent": "supervisor"
        }
    
    def _error_handler(self, state: MultiAgentState) -> MultiAgentState:
        """é”™è¯¯å¤„ç†æ™ºèƒ½ä½“ - å¤„ç†å’Œæ¢å¤é”™è¯¯"""
        print("ğŸš¨ é”™è¯¯å¤„ç†æ™ºèƒ½ä½“: å¤„ç†é”™è¯¯...")
        
        error_count = state.get("error_count", 0)
        print(f"   é”™è¯¯è®¡æ•°: {error_count}")
        
        # é‡ç½®é”™è¯¯è®¡æ•°å¹¶é‡‡å–æ¢å¤æªæ–½
        recovery_actions = [
            "é‡ç½®é”™è¯¯çŠ¶æ€",
            "æ¸…ç†æ— æ•ˆæ•°æ®",
            "è°ƒæ•´å¤„ç†ç­–ç•¥",
            "é™ä½è´¨é‡è¦æ±‚"
        ]
        
        print(f"   ğŸ”§ æ‰§è¡Œæ¢å¤æ“ä½œ: {', '.join(recovery_actions)}")
        
        # å»ºè®®åˆ‡æ¢åˆ°å¿«é€Ÿç­–ç•¥
        new_strategy = "fast" if state.get("strategy") != "fast" else "standard"
        
        return {
            **state,
            "error_count": 0,
            "strategy": new_strategy,
            "current_agent": "supervisor"
        }
    
    def _route_next_agent(self, state: MultiAgentState) -> str:
        """è·¯ç”±åˆ°ä¸‹ä¸€ä¸ªæ™ºèƒ½ä½“"""
        return state.get("current_agent", "end")
    
    def _get_state_summary(self, state: MultiAgentState) -> Dict[str, Any]:
        """è·å–çŠ¶æ€æ‘˜è¦"""
        return {
            "has_research": bool(state.get("research_data")),
            "has_analysis": bool(state.get("analysis_result")),
            "has_charts": bool(state.get("chart_data")),
            "has_report": bool(state.get("final_report")),
            "quality_score": state.get("quality_score"),
            "error_count": state.get("error_count", 0),
            "strategy": state.get("strategy", "standard")
        }

    async def run_baseline_execution(self) -> tuple[Dict[str, Any], MultiAgentState]:
        """è¿è¡ŒåŸºçº¿æ‰§è¡Œ"""
        print("=" * 60)
        print("ğŸš€ åŸºçº¿æ‰§è¡Œ - æ ‡å‡†ç­–ç•¥")
        print("=" * 60)
        
        config = {
            "configurable": {
                "thread_id": str(uuid.uuid4()),
            }
        }
        
        initial_state = {
            "task": "åˆ†æäººå·¥æ™ºèƒ½å¸‚åœºè¶‹åŠ¿å¹¶ç”ŸæˆæŠ¥å‘Š",
            "strategy": "standard",
            "current_agent": "supervisor"
        }
        
        result = self.graph.invoke(initial_state, config)
        
        print(f"\nğŸ“Š åŸºçº¿æ‰§è¡Œç»“æœ:")
        print(f"   è´¨é‡åˆ†æ•°: {result.get('quality_score', 0):.2f}/1.0")
        print(f"   é”™è¯¯æ¬¡æ•°: {result.get('error_count', 0)}")
        print(f"   ç­–ç•¥: {result.get('strategy', 'N/A')}")
        
        return config, result

    async def demonstrate_strategy_branching(self, base_config: Dict[str, Any]):
        """æ¼”ç¤ºç­–ç•¥åˆ†æ”¯æµ‹è¯•"""
        print("\n" + "=" * 60)
        print("ğŸŒ³ ç­–ç•¥åˆ†æ”¯æµ‹è¯•")
        print("=" * 60)
        
        # è·å–åŸºçº¿æ‰§è¡Œçš„æ£€æŸ¥ç‚¹ <mcreference link="https://langchain-ai.github.io/langgraph/concepts/time-travel/" index="0">0</mcreference>
        states = list(self.graph.get_state_history(base_config))
        if len(states) < 2:
            print("âŒ å†å²çŠ¶æ€ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œåˆ†æ”¯æµ‹è¯•")
            return
        
        # é€‰æ‹©ä¸€ä¸ªæ—©æœŸæ£€æŸ¥ç‚¹è¿›è¡Œåˆ†æ”¯
        early_checkpoint = None
        for state in reversed(states):
            if not state.values.get("research_data"):  # æ‰¾åˆ°ç ”ç©¶å¼€å§‹å‰çš„çŠ¶æ€
                early_checkpoint = state
                break
        
        if not early_checkpoint:
            early_checkpoint = states[-1]  # ä½¿ç”¨æœ€æ—©çš„çŠ¶æ€
        
        print(f"ğŸ¯ ä»æ£€æŸ¥ç‚¹åˆ›å»ºç­–ç•¥åˆ†æ”¯:")
        print(f"   æ£€æŸ¥ç‚¹: {early_checkpoint.config['configurable']['checkpoint_id'][:8]}...")
        
        strategies = ["deep", "fast"]
        branch_results = {}
        
        for strategy in strategies:
            print(f"\nğŸŒ¿ æµ‹è¯•ç­–ç•¥: {strategy}")
            
            # åˆ›å»ºåˆ†æ”¯å¹¶ä¿®æ”¹ç­–ç•¥ <mcreference link="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/" index="1">1</mcreference>
            branch_config = self.graph.update_state(
                base_config,
                {"strategy": strategy},
                checkpoint_id=early_checkpoint.config["configurable"]["checkpoint_id"]
            )
            
            # ä»åˆ†æ”¯ç»§ç»­æ‰§è¡Œ
            branch_result = self.graph.invoke(None, branch_config)
            branch_results[strategy] = branch_result
            
            print(f"   è´¨é‡åˆ†æ•°: {branch_result.get('quality_score', 0):.2f}/1.0")
            print(f"   é”™è¯¯æ¬¡æ•°: {branch_result.get('error_count', 0)}")
            
            # åˆ†æç ”ç©¶æ•°æ®å·®å¼‚
            research_data = branch_result.get('research_data', {})
            if research_data:
                print(f"   æ•°æ®ç‚¹æ•°: {research_data.get('data_points', 0)}")
                print(f"   ç½®ä¿¡åº¦: {research_data.get('confidence', 0):.2f}")
        
        # æ¯”è¾ƒç­–ç•¥æ•ˆæœ
        print(f"\nğŸ“ˆ ç­–ç•¥æ¯”è¾ƒ:")
        best_strategy = max(strategies, key=lambda s: branch_results[s].get('quality_score', 0))
        print(f"   æœ€ä½³ç­–ç•¥: {best_strategy}")
        
        for strategy in strategies:
            result = branch_results[strategy]
            quality = result.get('quality_score', 0)
            errors = result.get('error_count', 0)
            print(f"   {strategy}: è´¨é‡={quality:.2f}, é”™è¯¯={errors}")
        
        return branch_results

    async def demonstrate_error_recovery(self, base_config: Dict[str, Any]):
        """æ¼”ç¤ºé”™è¯¯æ¢å¤åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸ”§ é”™è¯¯æ¢å¤æ¼”ç¤º")
        print("=" * 60)
        
        # æ¨¡æ‹Ÿé”™è¯¯åœºæ™¯ï¼šå¼ºåˆ¶å¢åŠ é”™è¯¯è®¡æ•° <mcreference link="https://langchain-ai.github.io/langgraph/concepts/time-travel/" index="0">0</mcreference>
        states = list(self.graph.get_state_history(base_config))
        if not states:
            print("âŒ æ— å†å²çŠ¶æ€å¯ç”¨")
            return
        
        # æ‰¾åˆ°ä¸€ä¸ªä¸­é—´çŠ¶æ€
        middle_state = states[len(states)//2] if len(states) > 2 else states[0]
        
        print(f"ğŸ¯ æ¨¡æ‹Ÿé”™è¯¯åœºæ™¯:")
        print(f"   ä»æ£€æŸ¥ç‚¹: {middle_state.config['configurable']['checkpoint_id'][:8]}...")
        
        # åˆ›å»ºé”™è¯¯çŠ¶æ€
        error_config = self.graph.update_state(
            base_config,
            {"error_count": 3},  # è§¦å‘é”™è¯¯å¤„ç†
            checkpoint_id=middle_state.config["configurable"]["checkpoint_id"]
        )
        
        print("   ğŸ’¥ æ³¨å…¥é”™è¯¯: error_count = 3")
        
        # ä»é”™è¯¯çŠ¶æ€æ¢å¤æ‰§è¡Œ
        print("\nğŸš‘ æ‰§è¡Œé”™è¯¯æ¢å¤:")
        recovery_result = self.graph.invoke(None, error_config)
        
        print(f"   âœ… æ¢å¤åçŠ¶æ€:")
        print(f"      é”™è¯¯è®¡æ•°: {recovery_result.get('error_count', 0)}")
        print(f"      ç­–ç•¥è°ƒæ•´: {recovery_result.get('strategy', 'N/A')}")
        print(f"      æœ€ç»ˆè´¨é‡: {recovery_result.get('quality_score', 0):.2f}/1.0")
        
        # åˆ†ææ¢å¤æ•ˆæœ
        decision_history = recovery_result.get('decision_history', [])
        error_decisions = [d for d in decision_history if 'error' in d.get('decision', '').lower()]
        
        if error_decisions:
            print(f"\nğŸ” é”™è¯¯å¤„ç†å†³ç­–:")
            for decision in error_decisions[-2:]:  # æ˜¾ç¤ºæœ€è¿‘çš„é”™è¯¯å¤„ç†å†³ç­–
                print(f"      {decision['timestamp'][:19]}: {decision['decision']}")
        
        return recovery_result

    async def demonstrate_performance_analysis(self, configs: List[Dict[str, Any]]):
        """æ¼”ç¤ºæ€§èƒ½åˆ†æåŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("âš¡ æ€§èƒ½åˆ†æ")
        print("=" * 60)
        
        all_metrics = []
        
        for i, config in enumerate(configs):
            print(f"\nğŸ“Š åˆ†ææ‰§è¡Œè·¯å¾„ {i+1}:")
            
            # è·å–æ‰§è¡Œå†å² <mcreference link="https://langchain-ai.github.io/langgraph/concepts/time-travel/" index="0">0</mcreference>
            states = list(self.graph.get_state_history(config))
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            total_steps = len(states)
            agent_usage = {}
            error_points = []
            
            for state in reversed(states):
                # ç»Ÿè®¡æ™ºèƒ½ä½“ä½¿ç”¨æƒ…å†µ
                if state.values and 'current_agent' in state.values:
                    agent = state.values['current_agent']
                    agent_usage[agent] = agent_usage.get(agent, 0) + 1
                
                # è®°å½•é”™è¯¯ç‚¹
                if state.values and state.values.get('error_count', 0) > 0:
                    error_points.append(state.config['configurable']['checkpoint_id'][:8])
            
            # è·å–æœ€ç»ˆç»“æœ
            final_state = states[0].values if states else {}
            quality_score = final_state.get('quality_score', 0)
            
            metrics = {
                "total_steps": total_steps,
                "quality_score": quality_score,
                "agent_usage": agent_usage,
                "error_count": len(error_points),
                "efficiency": quality_score / max(total_steps, 1)
            }
            
            all_metrics.append(metrics)
            
            print(f"   æ€»æ­¥éª¤: {total_steps}")
            print(f"   è´¨é‡åˆ†æ•°: {quality_score:.2f}")
            print(f"   æ•ˆç‡æŒ‡æ ‡: {metrics['efficiency']:.3f}")
            print(f"   æ™ºèƒ½ä½“ä½¿ç”¨: {dict(list(agent_usage.items())[:3])}")  # æ˜¾ç¤ºå‰3ä¸ª
        
        # ç»¼åˆåˆ†æ
        if len(all_metrics) > 1:
            print(f"\nğŸ¯ ç»¼åˆæ€§èƒ½åˆ†æ:")
            avg_quality = sum(m['quality_score'] for m in all_metrics) / len(all_metrics)
            avg_steps = sum(m['total_steps'] for m in all_metrics) / len(all_metrics)
            avg_efficiency = sum(m['efficiency'] for m in all_metrics) / len(all_metrics)
            
            print(f"   å¹³å‡è´¨é‡: {avg_quality:.2f}")
            print(f"   å¹³å‡æ­¥éª¤: {avg_steps:.1f}")
            print(f"   å¹³å‡æ•ˆç‡: {avg_efficiency:.3f}")
            
            # æ‰¾å‡ºæœ€ä½³æ‰§è¡Œ
            best_execution = max(all_metrics, key=lambda m: m['efficiency'])
            best_index = all_metrics.index(best_execution)
            print(f"   æœ€ä½³æ‰§è¡Œ: è·¯å¾„ {best_index + 1} (æ•ˆç‡: {best_execution['efficiency']:.3f})")

    async def run_complete_advanced_demo(self):
        """è¿è¡Œå®Œæ•´çš„é«˜çº§æ¼”ç¤º"""
        print("ğŸ­ LangGraphé«˜çº§æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º")
        print("å¤šæ™ºèƒ½ä½“åä½œåœºæ™¯ä¸­çš„æ—¶é—´æ—…è¡Œã€åˆ†æ”¯æµ‹è¯•å’Œé”™è¯¯æ¢å¤")
        print("=" * 80)
        
        try:
            # 1. åŸºçº¿æ‰§è¡Œ
            base_config, base_result = await self.run_baseline_execution()
            
            # 2. ç­–ç•¥åˆ†æ”¯æµ‹è¯•
            branch_results = await self.demonstrate_strategy_branching(base_config)
            
            # 3. é”™è¯¯æ¢å¤æ¼”ç¤º
            recovery_result = await self.demonstrate_error_recovery(base_config)
            
            # 4. æ€§èƒ½åˆ†æ
            all_configs = [base_config]
            if branch_results:
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ”¶é›†æ‰€æœ‰åˆ†æ”¯çš„é…ç½®
                all_configs.extend([base_config] * len(branch_results))
            
            await self.demonstrate_performance_analysis(all_configs)
            
            print("\n" + "=" * 80)
            print("âœ… é«˜çº§æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
            print("\nğŸ¯ é«˜çº§åŠŸèƒ½æ¼”ç¤ºè¦ç‚¹:")
            print("1. âœ“ å¤šæ™ºèƒ½ä½“åä½œä¸­çš„æ—¶é—´æ—…è¡Œ")
            print("2. âœ“ ç­–ç•¥åˆ†æ”¯æµ‹è¯•å’Œæ¯”è¾ƒ")
            print("3. âœ“ é”™è¯¯æ¢å¤å’ŒçŠ¶æ€ä¿®å¤")
            print("4. âœ“ æ€§èƒ½åˆ†æå’Œè·¯å¾„ä¼˜åŒ–")
            print("5. âœ“ å¤æ‚å†³ç­–å†å²è¿½è¸ª")
            
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    demo = AdvancedTimeTravelDemo()
    await demo.run_complete_advanced_demo()


if __name__ == "__main__":
    asyncio.run(main())