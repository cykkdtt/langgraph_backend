#!/usr/bin/env python3
"""
LangGraph æµå¼å¤„ç†ç»¼åˆæ¼”ç¤º

åŸºäºå®˜æ–¹æ–‡æ¡£å­¦ä¹ ï¼Œæ¼”ç¤ºLangGraphçš„å„ç§æµå¼å¤„ç†åŠŸèƒ½ï¼š
1. å·¥ä½œæµè¿›åº¦æµå¼å¤„ç† - è·å–å›¾èŠ‚ç‚¹æ‰§è¡Œåçš„çŠ¶æ€æ›´æ–°
2. LLMä»¤ç‰Œæµå¼å¤„ç† - æµå¼ä¼ è¾“è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„ä»¤ç‰Œ
3. è‡ªå®šä¹‰æ›´æ–°æµå¼å¤„ç† - å‘å‡ºç”¨æˆ·å®šä¹‰çš„ä¿¡å·
4. å¤šç§æµå¼æ¨¡å¼ç»„åˆä½¿ç”¨
5. å·¥å…·ä¸­çš„æµå¼æ›´æ–°
6. æµå¼å¤„ç†çš„é”™è¯¯å¤„ç†å’Œä¸­æ–­æœºåˆ¶

å‚è€ƒæ–‡æ¡£ï¼š
- https://langchain-ai.github.io/langgraph/concepts/streaming/
- https://langchain-ai.github.io/langgraph/how-tos/streaming/
- https://langchain-ai.github.io/langgraph/cloud/how-tos/streaming/
"""

import asyncio
import json
import logging
from datetime import datetime
from typing import Dict, Any, List, AsyncGenerator, Optional
from dataclasses import dataclass

from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.config import get_stream_writer
from langgraph.prebuilt import create_react_agent

# å¯¼å…¥é¡¹ç›®ä¸­çš„æµå¼å¤„ç†ç»„ä»¶
from core.streaming import (
    StreamManager, StreamConfig, StreamMode, StreamEventType,
    StreamChunk, StreamState
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("streaming_demo")


@dataclass
class DemoState:
    """æ¼”ç¤ºçŠ¶æ€ç±»"""
    messages: List[Any]
    current_step: str = ""
    progress: float = 0.0
    data: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.data is None:
            self.data = {}


# åˆ›å»ºæ”¯æŒæµå¼æ›´æ–°çš„å·¥å…·
@tool
def weather_tool(city: str) -> str:
    """è·å–å¤©æ°”ä¿¡æ¯çš„å·¥å…·ï¼Œæ”¯æŒæµå¼æ›´æ–°"""
    # è·å–æµå¼å†™å…¥å™¨
    writer = get_stream_writer()
    
    # å‘é€è¿›åº¦æ›´æ–°
    writer(f"ğŸŒ æ­£åœ¨æŸ¥è¯¢ {city} çš„å¤©æ°”ä¿¡æ¯...")
    
    # æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
    import time
    time.sleep(1)
    
    writer(f"ğŸ“¡ è¿æ¥åˆ°å¤©æ°”æœåŠ¡...")
    time.sleep(0.5)
    
    writer(f"ğŸ“Š è§£æå¤©æ°”æ•°æ®...")
    time.sleep(0.5)
    
    # è¿”å›ç»“æœ
    result = f"ä»Šå¤©{city}çš„å¤©æ°”æ˜¯æ™´æœ—çš„ï¼Œæ¸©åº¦25Â°C"
    writer(f"âœ… å¤©æ°”æŸ¥è¯¢å®Œæˆ")
    
    return result


@tool
def data_analysis_tool(data: Dict[str, Any]) -> str:
    """æ•°æ®åˆ†æå·¥å…·ï¼Œæ”¯æŒæµå¼è¿›åº¦æ›´æ–°"""
    writer = get_stream_writer()
    
    total_items = len(data)
    writer(f"ğŸ“ˆ å¼€å§‹åˆ†æ {total_items} é¡¹æ•°æ®...")
    
    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†è¿‡ç¨‹
    for i, (key, value) in enumerate(data.items(), 1):
        progress = (i / total_items) * 100
        writer(f"ğŸ” å¤„ç†é¡¹ç›® {i}/{total_items}: {key} ({progress:.1f}%)")
        import time
        time.sleep(0.3)
    
    writer(f"âœ… æ•°æ®åˆ†æå®Œæˆï¼Œå‘ç° {total_items} ä¸ªå…³é”®æŒ‡æ ‡")
    
    return f"åˆ†æå®Œæˆï¼šå¤„ç†äº†{total_items}é¡¹æ•°æ®ï¼Œå‘ç°å…³é”®è¶‹åŠ¿å’Œæ¨¡å¼"


class StreamingWorkflowDemo:
    """æµå¼å·¥ä½œæµæ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.checkpointer = MemorySaver()
        self.stream_manager = StreamManager(self.checkpointer)
        
    def create_simple_workflow(self) -> StateGraph:
        """åˆ›å»ºç®€å•çš„å·¥ä½œæµå›¾"""
        
        def step1_node(state: DemoState) -> DemoState:
            """ç¬¬ä¸€æ­¥ï¼šæ•°æ®å‡†å¤‡"""
            logger.info("æ‰§è¡Œæ­¥éª¤1ï¼šæ•°æ®å‡†å¤‡")
            state.current_step = "æ•°æ®å‡†å¤‡"
            state.progress = 0.25
            state.data = {"users": 100, "orders": 250, "revenue": 15000}
            state.messages = add_messages(
                state.messages,
                [AIMessage(content="æ­¥éª¤1å®Œæˆï¼šæ•°æ®å‡†å¤‡å°±ç»ª")]
            )
            return state
        
        def step2_node(state: DemoState) -> DemoState:
            """ç¬¬äºŒæ­¥ï¼šæ•°æ®å¤„ç†"""
            logger.info("æ‰§è¡Œæ­¥éª¤2ï¼šæ•°æ®å¤„ç†")
            state.current_step = "æ•°æ®å¤„ç†"
            state.progress = 0.5
            # è°ƒç”¨æ•°æ®åˆ†æå·¥å…·
            result = data_analysis_tool.invoke(state.data)
            state.messages = add_messages(
                state.messages,
                [AIMessage(content=f"æ­¥éª¤2å®Œæˆï¼š{result}")]
            )
            return state
        
        def step3_node(state: DemoState) -> DemoState:
            """ç¬¬ä¸‰æ­¥ï¼šç»“æœç”Ÿæˆ"""
            logger.info("æ‰§è¡Œæ­¥éª¤3ï¼šç»“æœç”Ÿæˆ")
            state.current_step = "ç»“æœç”Ÿæˆ"
            state.progress = 1.0
            state.messages = add_messages(
                state.messages,
                [AIMessage(content="æ­¥éª¤3å®Œæˆï¼šæŠ¥å‘Šå·²ç”Ÿæˆ")]
            )
            return state
        
        # æ„å»ºå›¾
        workflow = StateGraph(DemoState)
        workflow.add_node("step1", step1_node)
        workflow.add_node("step2", step2_node)
        workflow.add_node("step3", step3_node)
        
        workflow.add_edge(START, "step1")
        workflow.add_edge("step1", "step2")
        workflow.add_edge("step2", "step3")
        workflow.add_edge("step3", END)
        
        return workflow.compile(checkpointer=self.checkpointer)
    
    async def demo_basic_streaming(self):
        """æ¼”ç¤ºåŸºç¡€æµå¼å¤„ç†"""
        logger.info("=== åŸºç¡€æµå¼å¤„ç†æ¼”ç¤º ===")
        
        graph = self.create_simple_workflow()
        
        # åˆå§‹çŠ¶æ€
        initial_state = DemoState(
            messages=[HumanMessage(content="å¼€å§‹æ•°æ®åˆ†ææµç¨‹")]
        )
        
        config = {"configurable": {"thread_id": "demo_basic_streaming"}}
        
        print("\nğŸ”„ æµå¼æ¨¡å¼: updates (çŠ¶æ€æ›´æ–°)")
        print("-" * 50)
        
        # ä½¿ç”¨ updates æ¨¡å¼æµå¼å¤„ç†
        async for chunk in graph.astream(initial_state, config, stream_mode="updates"):
            for node_name, node_output in chunk.items():
                print(f"ğŸ“ èŠ‚ç‚¹: {node_name}")
                print(f"   å½“å‰æ­¥éª¤: {node_output.current_step}")
                print(f"   è¿›åº¦: {node_output.progress * 100:.1f}%")
                if node_output.messages:
                    latest_message = node_output.messages[-1]
                    print(f"   æ¶ˆæ¯: {latest_message.content}")
                print()
    
    async def demo_values_streaming(self):
        """æ¼”ç¤ºå®Œæ•´çŠ¶æ€å€¼æµå¼å¤„ç†"""
        logger.info("=== å®Œæ•´çŠ¶æ€å€¼æµå¼å¤„ç†æ¼”ç¤º ===")
        
        graph = self.create_simple_workflow()
        
        initial_state = DemoState(
            messages=[HumanMessage(content="å¼€å§‹å®Œæ•´çŠ¶æ€æµå¼å¤„ç†")]
        )
        
        config = {"configurable": {"thread_id": "demo_values_streaming"}}
        
        print("\nğŸ”„ æµå¼æ¨¡å¼: values (å®Œæ•´çŠ¶æ€)")
        print("-" * 50)
        
        # ä½¿ç”¨ values æ¨¡å¼æµå¼å¤„ç†
        async for state in graph.astream(initial_state, config, stream_mode="values"):
            print(f"ğŸ“Š å®Œæ•´çŠ¶æ€æ›´æ–°:")
            print(f"   å½“å‰æ­¥éª¤: {state.current_step}")
            print(f"   è¿›åº¦: {state.progress * 100:.1f}%")
            print(f"   æ•°æ®é¡¹: {len(state.data) if state.data else 0}")
            print(f"   æ¶ˆæ¯æ•°: {len(state.messages)}")
            print()
    
    async def demo_custom_streaming(self):
        """æ¼”ç¤ºè‡ªå®šä¹‰æµå¼å¤„ç†"""
        logger.info("=== è‡ªå®šä¹‰æµå¼å¤„ç†æ¼”ç¤º ===")
        
        # åˆ›å»ºåŒ…å«å·¥å…·çš„ç®€å•å›¾
        def tool_node(state: DemoState) -> DemoState:
            """è°ƒç”¨å·¥å…·çš„èŠ‚ç‚¹"""
            # è°ƒç”¨å¤©æ°”å·¥å…·
            weather_result = weather_tool.invoke({"city": "åŒ—äº¬"})
            
            # è°ƒç”¨æ•°æ®åˆ†æå·¥å…·
            analysis_result = data_analysis_tool.invoke({
                "sales": 1000,
                "users": 500,
                "conversion": 0.05
            })
            
            state.messages = add_messages(
                state.messages,
                [
                    AIMessage(content=f"å¤©æ°”æŸ¥è¯¢ç»“æœ: {weather_result}"),
                    AIMessage(content=f"æ•°æ®åˆ†æç»“æœ: {analysis_result}")
                ]
            )
            return state
        
        workflow = StateGraph(DemoState)
        workflow.add_node("tools", tool_node)
        workflow.add_edge(START, "tools")
        workflow.add_edge("tools", END)
        
        graph = workflow.compile(checkpointer=self.checkpointer)
        
        initial_state = DemoState(
            messages=[HumanMessage(content="æ‰§è¡Œå·¥å…·è°ƒç”¨")]
        )
        
        config = {"configurable": {"thread_id": "demo_custom_streaming"}}
        
        print("\nğŸ”„ æµå¼æ¨¡å¼: custom (è‡ªå®šä¹‰æ›´æ–°)")
        print("-" * 50)
        
        # ä½¿ç”¨ custom æ¨¡å¼æµå¼å¤„ç†
        async for chunk in graph.astream(initial_state, config, stream_mode="custom"):
            print(f"ğŸ”§ è‡ªå®šä¹‰æ›´æ–°: {chunk}")
    
    async def demo_multiple_stream_modes(self):
        """æ¼”ç¤ºå¤šç§æµå¼æ¨¡å¼ç»„åˆ"""
        logger.info("=== å¤šç§æµå¼æ¨¡å¼ç»„åˆæ¼”ç¤º ===")
        
        graph = self.create_simple_workflow()
        
        initial_state = DemoState(
            messages=[HumanMessage(content="å¤šæ¨¡å¼æµå¼å¤„ç†")]
        )
        
        config = {"configurable": {"thread_id": "demo_multiple_modes"}}
        
        print("\nğŸ”„ æµå¼æ¨¡å¼: ['updates', 'custom']")
        print("-" * 50)
        
        # ä½¿ç”¨å¤šç§æµå¼æ¨¡å¼
        async for stream_mode, chunk in graph.astream(
            initial_state, 
            config, 
            stream_mode=["updates", "custom"]
        ):
            print(f"ğŸ“¡ æ¨¡å¼: {stream_mode}")
            if stream_mode == "updates":
                for node_name, node_output in chunk.items():
                    print(f"   èŠ‚ç‚¹æ›´æ–°: {node_name} -> {node_output.current_step}")
            elif stream_mode == "custom":
                print(f"   è‡ªå®šä¹‰æ•°æ®: {chunk}")
            print()
    
    async def demo_stream_manager_integration(self):
        """æ¼”ç¤ºä¸é¡¹ç›®æµå¼ç®¡ç†å™¨çš„é›†æˆ"""
        logger.info("=== æµå¼ç®¡ç†å™¨é›†æˆæ¼”ç¤º ===")
        
        graph = self.create_simple_workflow()
        
        initial_state = DemoState(
            messages=[HumanMessage(content="æµå¼ç®¡ç†å™¨é›†æˆæµ‹è¯•")]
        )
        
        config = {"configurable": {"thread_id": "demo_stream_manager"}}
        
        # åˆ›å»ºæµå¼é…ç½®
        stream_config = StreamConfig(
            modes=[StreamMode.UPDATES, StreamMode.VALUES],
            buffer_size=50,
            timeout=60
        )
        
        print("\nğŸ”„ ä½¿ç”¨é¡¹ç›®æµå¼ç®¡ç†å™¨")
        print("-" * 50)
        
        # ä½¿ç”¨é¡¹ç›®çš„æµå¼ç®¡ç†å™¨
        async for chunk in self.stream_manager.stream_graph_execution(
            graph, initial_state, config, stream_config
        ):
            print(f"ğŸ¯ {chunk.chunk_type.value}: {chunk.content}")
            if chunk.metadata:
                print(f"   å…ƒæ•°æ®: {json.dumps(chunk.metadata, ensure_ascii=False, indent=2)}")
            print()
    
    async def demo_error_handling_streaming(self):
        """æ¼”ç¤ºæµå¼å¤„ç†ä¸­çš„é”™è¯¯å¤„ç†"""
        logger.info("=== æµå¼å¤„ç†é”™è¯¯å¤„ç†æ¼”ç¤º ===")
        
        def error_node(state: DemoState) -> DemoState:
            """ä¼šäº§ç”Ÿé”™è¯¯çš„èŠ‚ç‚¹"""
            state.current_step = "é”™è¯¯å¤„ç†æµ‹è¯•"
            # æ•…æ„æŠ›å‡ºå¼‚å¸¸
            raise ValueError("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é”™è¯¯")
        
        def recovery_node(state: DemoState) -> DemoState:
            """æ¢å¤èŠ‚ç‚¹"""
            state.current_step = "é”™è¯¯æ¢å¤"
            state.messages = add_messages(
                state.messages,
                [AIMessage(content="å·²ä»é”™è¯¯ä¸­æ¢å¤")]
            )
            return state
        
        workflow = StateGraph(DemoState)
        workflow.add_node("error_step", error_node)
        workflow.add_node("recovery", recovery_node)
        
        workflow.add_edge(START, "error_step")
        workflow.add_edge("error_step", "recovery")
        workflow.add_edge("recovery", END)
        
        graph = workflow.compile(checkpointer=self.checkpointer)
        
        initial_state = DemoState(
            messages=[HumanMessage(content="é”™è¯¯å¤„ç†æµ‹è¯•")]
        )
        
        config = {"configurable": {"thread_id": "demo_error_handling"}}
        
        print("\nğŸ”„ æµå¼å¤„ç†é”™è¯¯å¤„ç†")
        print("-" * 50)
        
        try:
            async for chunk in graph.astream(initial_state, config, stream_mode="updates"):
                for node_name, node_output in chunk.items():
                    print(f"ğŸ“ èŠ‚ç‚¹: {node_name}")
                    print(f"   æ­¥éª¤: {node_output.current_step}")
                    print()
        except Exception as e:
            print(f"âŒ æ•è·åˆ°é”™è¯¯: {e}")
            print("ğŸ”§ é”™è¯¯å¤„ç†æœºåˆ¶å·²æ¿€æ´»")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ LangGraph æµå¼å¤„ç†ç»¼åˆæ¼”ç¤º")
    print("=" * 60)
    print("åŸºäºå®˜æ–¹æ–‡æ¡£å­¦ä¹ çš„æµå¼å¤„ç†åŠŸèƒ½æ¼”ç¤º")
    print("å‚è€ƒæ–‡æ¡£:")
    print("- https://langchain-ai.github.io/langgraph/concepts/streaming/")
    print("- https://langchain-ai.github.io/langgraph/how-tos/streaming/")
    print("- https://langchain-ai.github.io/langgraph/cloud/how-tos/streaming/")
    print("=" * 60)
    
    demo = StreamingWorkflowDemo()
    
    # è¿è¡Œå„ç§æ¼”ç¤º
    await demo.demo_basic_streaming()
    await asyncio.sleep(1)
    
    await demo.demo_values_streaming()
    await asyncio.sleep(1)
    
    await demo.demo_custom_streaming()
    await asyncio.sleep(1)
    
    await demo.demo_multiple_stream_modes()
    await asyncio.sleep(1)
    
    await demo.demo_stream_manager_integration()
    await asyncio.sleep(1)
    
    await demo.demo_error_handling_streaming()
    
    print("\nâœ… æµå¼å¤„ç†æ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ“š å­¦ä¹ æ€»ç»“:")
    print("1. LangGraphæ”¯æŒå¤šç§æµå¼æ¨¡å¼ï¼švalues, updates, messages, custom, debug")
    print("2. å¯ä»¥åœ¨å·¥å…·ä¸­ä½¿ç”¨get_stream_writer()å‘é€è‡ªå®šä¹‰æ›´æ–°")
    print("3. æ”¯æŒå¤šç§æµå¼æ¨¡å¼åŒæ—¶ä½¿ç”¨")
    print("4. æµå¼å¤„ç†å…·æœ‰å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶")
    print("5. å¯ä»¥ä¸é¡¹ç›®è‡ªå®šä¹‰çš„æµå¼ç®¡ç†å™¨é›†æˆ")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()