#!/usr/bin/env python3
"""
LangGraph æµå¼å¤„ç†å®æˆ˜æ¼”ç¤º

åŸºäºå®˜æ–¹æ–‡æ¡£å­¦ä¹ çš„æµå¼å¤„ç†åŠŸèƒ½å®ç°ï¼Œå±•ç¤ºï¼š
1. å¤šç§æµå¼æ¨¡å¼çš„ä½¿ç”¨
2. å·¥å…·ä¸­çš„è‡ªå®šä¹‰æµå¼æ›´æ–°
3. LLMä»¤ç‰Œæµå¼å¤„ç†
4. é”™è¯¯å¤„ç†å’Œæ¢å¤
5. ä¸é¡¹ç›®æµå¼ç®¡ç†å™¨çš„é›†æˆ
"""

import asyncio
import json
import time
from typing import Dict, Any, List, AsyncGenerator, Optional
from dataclasses import dataclass
from enum import Enum

from langgraph import StateGraph, END
from langgraph.graph import Graph
from langgraph.config import get_stream_writer
from langgraph.checkpoint.memory import MemorySaver

# å¯¼å…¥é¡¹ç›®çš„æµå¼ç®¡ç†å™¨
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.streaming.stream_manager import StreamManager, StreamConfig, StreamMode
from core.streaming.stream_types import StreamEventType


class DemoState(Dict[str, Any]):
    """æ¼”ç¤ºçŠ¶æ€ç±»"""
    messages: List[Dict[str, str]]
    progress: float
    current_task: str
    results: List[str]
    error_count: int


class StreamingDemoApp:
    """LangGraphæµå¼å¤„ç†æ¼”ç¤ºåº”ç”¨"""
    
    def __init__(self):
        self.checkpointer = MemorySaver()
        self.stream_manager = StreamManager(self.checkpointer)
        
    def create_demo_graph(self) -> StateGraph:
        """åˆ›å»ºæ¼”ç¤ºå›¾"""
        
        def start_node(state: DemoState) -> DemoState:
            """å¼€å§‹èŠ‚ç‚¹"""
            writer = get_stream_writer()
            writer("ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
            
            return {
                **state,
                "current_task": "åˆå§‹åŒ–",
                "progress": 0.1,
                "messages": state.get("messages", []) + [
                    {"role": "system", "content": "å·¥ä½œæµå·²å¯åŠ¨"}
                ]
            }
        
        def data_processing_node(state: DemoState) -> DemoState:
            """æ•°æ®å¤„ç†èŠ‚ç‚¹ - å±•ç¤ºå·¥å…·ä¸­çš„æµå¼æ›´æ–°"""
            writer = get_stream_writer()
            
            # æ¨¡æ‹Ÿæ•°æ®å¤„ç†è¿‡ç¨‹
            data_items = ["ç”¨æˆ·æ•°æ®", "äº§å“ä¿¡æ¯", "è®¢å•è®°å½•", "åˆ†ææŠ¥å‘Š", "ç»Ÿè®¡æ•°æ®"]
            results = []
            
            writer("ğŸ“Š å¼€å§‹æ•°æ®å¤„ç†...")
            
            for i, item in enumerate(data_items):
                # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                time.sleep(0.5)
                
                # å‘é€è¿›åº¦æ›´æ–°
                progress = (i + 1) / len(data_items)
                writer(f"å¤„ç† {item}... ({progress:.1%})")
                
                results.append(f"å·²å¤„ç†: {item}")
            
            writer("âœ… æ•°æ®å¤„ç†å®Œæˆ!")
            
            return {
                **state,
                "current_task": "æ•°æ®å¤„ç†",
                "progress": 0.5,
                "results": results
            }
        
        def llm_simulation_node(state: DemoState) -> DemoState:
            """LLMæ¨¡æ‹ŸèŠ‚ç‚¹ - å±•ç¤ºä»¤ç‰Œæµå¼å¤„ç†"""
            writer = get_stream_writer()
            
            # æ¨¡æ‹ŸLLMç”Ÿæˆè¿‡ç¨‹
            response_text = "åŸºäºå¤„ç†çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼šæ•°æ®è´¨é‡è‰¯å¥½ï¼Œç”¨æˆ·æ´»è·ƒåº¦è¾ƒé«˜ï¼Œäº§å“é”€å”®è¶‹åŠ¿ç§¯æã€‚"
            
            writer("ğŸ¤– LLMå¼€å§‹ç”Ÿæˆå“åº”...")
            
            # æ¨¡æ‹Ÿä»¤ç‰Œæµå¼ç”Ÿæˆ
            for i, char in enumerate(response_text):
                if i % 5 == 0:  # æ¯5ä¸ªå­—ç¬¦å‘é€ä¸€æ¬¡æ›´æ–°
                    writer(f"ç”Ÿæˆè¿›åº¦: {response_text[:i+5]}")
                time.sleep(0.1)
            
            writer("ğŸ¯ LLMå“åº”ç”Ÿæˆå®Œæˆ!")
            
            return {
                **state,
                "current_task": "LLMç”Ÿæˆ",
                "progress": 0.8,
                "messages": state.get("messages", []) + [
                    {"role": "assistant", "content": response_text}
                ]
            }
        
        def finalization_node(state: DemoState) -> DemoState:
            """å®ŒæˆèŠ‚ç‚¹"""
            writer = get_stream_writer()
            writer("ğŸ‰ å·¥ä½œæµæ‰§è¡Œå®Œæˆ!")
            
            return {
                **state,
                "current_task": "å®Œæˆ",
                "progress": 1.0
            }
        
        # æ„å»ºå›¾
        graph = StateGraph(DemoState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("start", start_node)
        graph.add_node("data_processing", data_processing_node)
        graph.add_node("llm_simulation", llm_simulation_node)
        graph.add_node("finalization", finalization_node)
        
        # æ·»åŠ è¾¹
        graph.add_edge("start", "data_processing")
        graph.add_edge("data_processing", "llm_simulation")
        graph.add_edge("llm_simulation", "finalization")
        graph.add_edge("finalization", END)
        
        # è®¾ç½®å…¥å£ç‚¹
        graph.set_entry_point("start")
        
        return graph.compile(checkpointer=self.checkpointer)
    
    async def demo_basic_streaming(self):
        """æ¼”ç¤ºåŸºç¡€æµå¼å¤„ç†"""
        print("\n" + "="*60)
        print("ğŸ”„ åŸºç¡€æµå¼å¤„ç†æ¼”ç¤º (updatesæ¨¡å¼)")
        print("="*60)
        
        graph = self.create_demo_graph()
        
        input_data = {
            "messages": [{"role": "user", "content": "è¯·å¤„ç†æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"}],
            "progress": 0.0,
            "current_task": "",
            "results": [],
            "error_count": 0
        }
        
        config = {"configurable": {"thread_id": "demo_basic"}}
        
        async for chunk in graph.astream(input_data, config, stream_mode="updates"):
            for node_name, node_output in chunk.items():
                print(f"ğŸ“ èŠ‚ç‚¹: {node_name}")
                print(f"   ä»»åŠ¡: {node_output.get('current_task', 'N/A')}")
                print(f"   è¿›åº¦: {node_output.get('progress', 0):.1%}")
                print()
    
    async def demo_custom_streaming(self):
        """æ¼”ç¤ºè‡ªå®šä¹‰æµå¼å¤„ç†"""
        print("\n" + "="*60)
        print("ğŸ¨ è‡ªå®šä¹‰æµå¼å¤„ç†æ¼”ç¤º (customæ¨¡å¼)")
        print("="*60)
        
        graph = self.create_demo_graph()
        
        input_data = {
            "messages": [{"role": "user", "content": "è¯·å¤„ç†æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"}],
            "progress": 0.0,
            "current_task": "",
            "results": [],
            "error_count": 0
        }
        
        config = {"configurable": {"thread_id": "demo_custom"}}
        
        async for chunk in graph.astream(input_data, config, stream_mode="custom"):
            print(f"ğŸ’¬ è‡ªå®šä¹‰æ›´æ–°: {chunk}")
    
    async def demo_multi_mode_streaming(self):
        """æ¼”ç¤ºå¤šæ¨¡å¼æµå¼å¤„ç†"""
        print("\n" + "="*60)
        print("ğŸ”€ å¤šæ¨¡å¼æµå¼å¤„ç†æ¼”ç¤º (updates + custom)")
        print("="*60)
        
        graph = self.create_demo_graph()
        
        input_data = {
            "messages": [{"role": "user", "content": "è¯·å¤„ç†æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"}],
            "progress": 0.0,
            "current_task": "",
            "results": [],
            "error_count": 0
        }
        
        config = {"configurable": {"thread_id": "demo_multi"}}
        
        async for stream_mode, chunk in graph.astream(
            input_data, config, stream_mode=["updates", "custom"]
        ):
            if stream_mode == "updates":
                for node_name, node_output in chunk.items():
                    print(f"ğŸ“Š [æ›´æ–°] èŠ‚ç‚¹: {node_name}, è¿›åº¦: {node_output.get('progress', 0):.1%}")
            elif stream_mode == "custom":
                print(f"ğŸ’¬ [è‡ªå®šä¹‰] {chunk}")
    
    async def demo_stream_manager_integration(self):
        """æ¼”ç¤ºä¸é¡¹ç›®æµå¼ç®¡ç†å™¨çš„é›†æˆ"""
        print("\n" + "="*60)
        print("ğŸ”§ æµå¼ç®¡ç†å™¨é›†æˆæ¼”ç¤º")
        print("="*60)
        
        graph = self.create_demo_graph()
        
        input_data = {
            "messages": [{"role": "user", "content": "è¯·å¤„ç†æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š"}],
            "progress": 0.0,
            "current_task": "",
            "results": [],
            "error_count": 0
        }
        
        config = {"configurable": {"thread_id": "demo_manager"}}
        
        # é…ç½®æµå¼ç®¡ç†å™¨
        stream_config = StreamConfig(
            modes=[StreamMode.UPDATES, StreamMode.CUSTOM],
            buffer_size=100,
            timeout=30
        )
        
        # æ³¨å†Œäº‹ä»¶å¤„ç†å™¨
        def on_progress_update(event):
            if event.event_type == StreamEventType.PROGRESS_UPDATE:
                print(f"ğŸ¯ [ç®¡ç†å™¨] è¿›åº¦æ›´æ–°: {event.data}")
        
        def on_custom_event(event):
            if event.event_type == StreamEventType.CUSTOM_EVENT:
                print(f"ğŸ¨ [ç®¡ç†å™¨] è‡ªå®šä¹‰äº‹ä»¶: {event.data}")
        
        self.stream_manager.register_event_handler(StreamEventType.PROGRESS_UPDATE, on_progress_update)
        self.stream_manager.register_event_handler(StreamEventType.CUSTOM_EVENT, on_custom_event)
        
        try:
            async for chunk in self.stream_manager.stream_graph_execution(
                graph, input_data, config, stream_config
            ):
                print(f"ğŸ“¦ [ç®¡ç†å™¨] æµå¼å—: {chunk.chunk_type.value} - {chunk.content}")
        except Exception as e:
            print(f"âŒ æµå¼å¤„ç†é”™è¯¯: {e}")
    
    async def demo_error_handling(self):
        """æ¼”ç¤ºé”™è¯¯å¤„ç†"""
        print("\n" + "="*60)
        print("âš ï¸  é”™è¯¯å¤„ç†æ¼”ç¤º")
        print("="*60)
        
        def error_node(state: DemoState) -> DemoState:
            """æ•…æ„äº§ç”Ÿé”™è¯¯çš„èŠ‚ç‚¹"""
            writer = get_stream_writer()
            writer("âš ï¸ å³å°†è§¦å‘é”™è¯¯...")
            
            # æ¨¡æ‹Ÿé”™è¯¯
            if state.get("error_count", 0) < 1:
                writer("âŒ å‘ç”Ÿé”™è¯¯ï¼Œæ­£åœ¨é‡è¯•...")
                raise ValueError("æ¨¡æ‹Ÿçš„å¤„ç†é”™è¯¯")
            
            writer("âœ… é”™è¯¯å·²æ¢å¤!")
            return {**state, "current_task": "é”™è¯¯æ¢å¤"}
        
        # åˆ›å»ºåŒ…å«é”™è¯¯å¤„ç†çš„å›¾
        graph = StateGraph(DemoState)
        graph.add_node("error_node", error_node)
        graph.add_edge("error_node", END)
        graph.set_entry_point("error_node")
        
        compiled_graph = graph.compile(checkpointer=self.checkpointer)
        
        input_data = {
            "messages": [],
            "progress": 0.0,
            "current_task": "",
            "results": [],
            "error_count": 0
        }
        
        config = {"configurable": {"thread_id": "demo_error"}}
        
        try:
            async for chunk in compiled_graph.astream(input_data, config, stream_mode="custom"):
                print(f"ğŸ’¬ é”™è¯¯å¤„ç†æ›´æ–°: {chunk}")
        except Exception as e:
            print(f"âŒ æ•è·åˆ°é”™è¯¯: {e}")
            print("ğŸ”„ å®ç°é”™è¯¯æ¢å¤é€»è¾‘...")
            
            # æ›´æ–°é”™è¯¯è®¡æ•°å¹¶é‡è¯•
            input_data["error_count"] = 1
            config["configurable"]["thread_id"] = "demo_error_retry"
            
            print("ğŸ”„ é‡è¯•æ‰§è¡Œ...")
            async for chunk in compiled_graph.astream(input_data, config, stream_mode="custom"):
                print(f"ğŸ’¬ é‡è¯•æ›´æ–°: {chunk}")
    
    async def run_all_demos(self):
        """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
        print("ğŸ¬ LangGraph æµå¼å¤„ç†å®æˆ˜æ¼”ç¤º")
        print("åŸºäºå®˜æ–¹æ–‡æ¡£å­¦ä¹ çš„æµå¼å¤„ç†åŠŸèƒ½")
        
        # è¿è¡Œå„ç§æ¼”ç¤º
        await self.demo_basic_streaming()
        await self.demo_custom_streaming()
        await self.demo_multi_mode_streaming()
        await self.demo_stream_manager_integration()
        await self.demo_error_handling()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
        print("="*60)
        print("\nğŸ“š å­¦ä¹ æ€»ç»“:")
        print("1. âœ… æŒæ¡äº†å¤šç§æµå¼æ¨¡å¼çš„ä½¿ç”¨")
        print("2. âœ… å­¦ä¼šäº†åœ¨å·¥å…·ä¸­å‘é€è‡ªå®šä¹‰æ›´æ–°")
        print("3. âœ… äº†è§£äº†LLMä»¤ç‰Œæµå¼å¤„ç†")
        print("4. âœ… å®ç°äº†é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶")
        print("5. âœ… é›†æˆäº†é¡¹ç›®çš„æµå¼ç®¡ç†å™¨")
        print("\nğŸš€ ç°åœ¨å¯ä»¥åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨è¿™äº›æµå¼å¤„ç†æŠ€æœ¯!")


async def main():
    """ä¸»å‡½æ•°"""
    demo_app = StreamingDemoApp()
    await demo_app.run_all_demos()


if __name__ == "__main__":
    asyncio.run(main())