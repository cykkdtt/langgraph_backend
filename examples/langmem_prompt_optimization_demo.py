#!/usr/bin/env python3
"""
LangMem æç¤ºè¯ä¼˜åŒ–æ¼”ç¤º

å±•ç¤ºå¦‚ä½•ä½¿ç”¨LangMemçš„æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½æ¥æ”¹è¿›æ™ºèƒ½ä½“çš„ç³»ç»Ÿæç¤ºè¯ã€‚
åŒ…æ‹¬ï¼š
1. å•ä¸ªæ™ºèƒ½ä½“æç¤ºè¯ä¼˜åŒ–
2. å¤šæ™ºèƒ½ä½“ç³»ç»ŸååŒä¼˜åŒ–
3. åŸºäºç”¨æˆ·åé¦ˆçš„æŒç»­æ”¹è¿›
"""

import asyncio
import os
import json
from datetime import datetime
from typing import Dict, Any, List, Tuple
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†langmem
try:
    from langmem import create_prompt_optimizer, create_multi_prompt_optimizer
    LANGMEM_AVAILABLE = True
except ImportError:
    LANGMEM_AVAILABLE = False
    print("âš ï¸  LangMemæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¼”ç¤º")


class PromptOptimizationDemo:
    """æç¤ºè¯ä¼˜åŒ–æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.model_name = "anthropic:claude-3-5-sonnet-latest"
        
    async def demo_single_agent_optimization(self):
        """æ¼”ç¤ºå•ä¸ªæ™ºèƒ½ä½“çš„æç¤ºè¯ä¼˜åŒ–"""
        print("\n" + "="*60)
        print("ğŸ¯ å•ä¸ªæ™ºèƒ½ä½“æç¤ºè¯ä¼˜åŒ–æ¼”ç¤º")
        print("="*60)
        
        # æ¨¡æ‹Ÿå¯¹è¯å†å²å’Œåé¦ˆ
        trajectories = [
            # å¯¹è¯1ï¼šç”¨æˆ·ä¸æ»¡æ„å›ç­”çš„è¯¦ç»†ç¨‹åº¦
            (
                [
                    {"role": "user", "content": "è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ "},
                    {"role": "assistant", "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ã€‚"},
                    {"role": "user", "content": "å¤ªç®€å•äº†ï¼Œæˆ‘éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Š"}
                ],
                {"feedback": "å›ç­”å¤ªç®€å•ï¼Œéœ€è¦æ›´è¯¦ç»†çš„æŠ€æœ¯è§£é‡Š"}
            ),
            
            # å¯¹è¯2ï¼šç”¨æˆ·æ»¡æ„çš„å›ç­”
            (
                [
                    {"role": "user", "content": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ"},
                    {"role": "assistant", "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚å®ƒåŒ…æ‹¬ä»¥ä¸‹å…³é”®æ¦‚å¿µï¼š\n1. ç¥ç»ç½‘ç»œæ¶æ„\n2. åå‘ä¼ æ’­ç®—æ³•\n3. æ¢¯åº¦ä¸‹é™ä¼˜åŒ–\n4. æ¿€æ´»å‡½æ•°çš„ä½œç”¨\n\nåº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ç­‰ã€‚"},
                ],
                {"score": 0.9, "comment": "è¯¦ç»†ä¸”ç»“æ„åŒ–ï¼Œå¾ˆå¥½çš„è§£é‡Š"}
            ),
            
            # å¯¹è¯3ï¼šéœ€è¦æ›´å¤šå®ä¾‹
            (
                [
                    {"role": "user", "content": "ç¥ç»ç½‘ç»œæ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ"},
                    {"role": "assistant", "content": "ç¥ç»ç½‘ç»œé€šè¿‡å±‚å±‚è¿æ¥çš„èŠ‚ç‚¹å¤„ç†ä¿¡æ¯ï¼Œæ¯ä¸ªè¿æ¥éƒ½æœ‰æƒé‡ã€‚"},
                    {"role": "user", "content": "èƒ½ç»™ä¸ªå…·ä½“ä¾‹å­å—ï¼Ÿ"}
                ],
                {"feedback": "éœ€è¦å…·ä½“çš„ä¾‹å­æ¥è¯´æ˜æ¦‚å¿µ"}
            )
        ]
        
        # åŸå§‹æç¤ºè¯
        original_prompt = "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€‚"
        
        print(f"ğŸ“ åŸå§‹æç¤ºè¯ï¼š\n{original_prompt}\n")
        
        if LANGMEM_AVAILABLE:
            # ä½¿ç”¨gradientç­–ç•¥ä¼˜åŒ–
            optimizer = create_prompt_optimizer(
                self.model_name,
                kind="gradient",
                config={
                    "max_reflection_steps": 2,
                    "min_reflection_steps": 1
                }
            )
            
            try:
                optimized_prompt = await optimizer.ainvoke({
                    "trajectories": trajectories,
                    "prompt": original_prompt
                })
                
                print(f"âœ¨ ä¼˜åŒ–åçš„æç¤ºè¯ï¼š\n{optimized_prompt}\n")
                
            except Exception as e:
                print(f"âŒ ä¼˜åŒ–å¤±è´¥: {e}")
                self._show_mock_optimization()
        else:
            self._show_mock_optimization()
    
    def _show_mock_optimization(self):
        """æ˜¾ç¤ºæ¨¡æ‹Ÿçš„ä¼˜åŒ–ç»“æœ"""
        mock_optimized = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæŠ€æœ¯åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·æ·±å…¥ç†è§£æŠ€æœ¯æ¦‚å¿µã€‚åœ¨å›ç­”æ—¶è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **è¯¦ç»†è§£é‡Š**ï¼šæä¾›å…¨é¢ã€æ·±å…¥çš„æŠ€æœ¯è§£é‡Šï¼Œä¸è¦è¿‡äºç®€åŒ–
2. **ç»“æ„åŒ–å›ç­”**ï¼šä½¿ç”¨æ¸…æ™°çš„ç»“æ„ï¼ŒåŒ…æ‹¬è¦ç‚¹åˆ—è¡¨ã€æ­¥éª¤è¯´æ˜ç­‰
3. **å…·ä½“ç¤ºä¾‹**ï¼šæ€»æ˜¯åŒ…å«å…·ä½“çš„ä¾‹å­æ¥è¯´æ˜æŠ½è±¡æ¦‚å¿µ
4. **æ¸è¿›å¼è§£é‡Š**ï¼šä»åŸºç¡€æ¦‚å¿µå¼€å§‹ï¼Œé€æ­¥æ·±å…¥åˆ°æŠ€æœ¯ç»†èŠ‚
5. **å®é™…åº”ç”¨**ï¼šè¯´æ˜æ¦‚å¿µåœ¨å®é™…ä¸­çš„åº”ç”¨åœºæ™¯

ç¡®ä¿ä½ çš„å›ç­”æ—¢æœ‰æŠ€æœ¯æ·±åº¦ï¼Œåˆæ˜“äºç†è§£ã€‚"""
        
        print(f"âœ¨ æ¨¡æ‹Ÿä¼˜åŒ–åçš„æç¤ºè¯ï¼š\n{mock_optimized}\n")
    
    async def demo_multi_agent_optimization(self):
        """æ¼”ç¤ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ååŒä¼˜åŒ–"""
        print("\n" + "="*60)
        print("ğŸ¤ å¤šæ™ºèƒ½ä½“ç³»ç»ŸååŒä¼˜åŒ–æ¼”ç¤º")
        print("="*60)
        
        # å®šä¹‰å¤šä¸ªæ™ºèƒ½ä½“çš„æç¤ºè¯
        agent_prompts = [
            {
                "name": "researcher",
                "prompt": "ä½ æ˜¯ä¸€ä¸ªç ”ç©¶å‘˜ï¼Œè´Ÿè´£æ”¶é›†å’Œåˆ†ææŠ€æœ¯ä¿¡æ¯ã€‚"
            },
            {
                "name": "writer",
                "prompt": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯å†™ä½œä¸“å®¶ï¼Œè´Ÿè´£å°†ç ”ç©¶ç»“æœå†™æˆæ¸…æ™°çš„æŠ¥å‘Šã€‚"
            },
            {
                "name": "reviewer",
                "prompt": "ä½ æ˜¯ä¸€ä¸ªè´¨é‡å®¡æ ¸å‘˜ï¼Œè´Ÿè´£æ£€æŸ¥æŠ¥å‘Šçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚"
            }
        ]
        
        # æ¨¡æ‹Ÿå›¢é˜Ÿåä½œçš„å¯¹è¯å†å²
        team_conversations = [
            # åä½œæ¡ˆä¾‹1ï¼šç¼ºå°‘æŠ€æœ¯ç»†èŠ‚
            (
                [
                    {"role": "user", "content": "ç ”ç©¶ä¸€ä¸‹æœ€æ–°çš„Transformeræ¶æ„"},
                    {"role": "assistant", "content": "æ‰¾åˆ°äº†ä¸€äº›å…³äºTransformerçš„åŸºæœ¬ä¿¡æ¯..."},  # researcher
                    {"role": "assistant", "content": "åŸºäºç ”ç©¶ï¼ŒTransformeræ˜¯ä¸€ç§æ³¨æ„åŠ›æœºåˆ¶..."},  # writer
                    {"role": "assistant", "content": "æŠ¥å‘Šç¼ºå°‘å…·ä½“çš„æŠ€æœ¯å®ç°ç»†èŠ‚"},  # reviewer
                    {"role": "user", "content": "ç¡®å®éœ€è¦æ›´å¤šæŠ€æœ¯ç»†èŠ‚"}
                ],
                {"feedback": "ç ”ç©¶ä¸å¤Ÿæ·±å…¥ï¼Œå†™ä½œç¼ºå°‘æŠ€æœ¯ç»†èŠ‚"}
            ),
            
            # åä½œæ¡ˆä¾‹2ï¼šæˆåŠŸçš„åä½œ
            (
                [
                    {"role": "user", "content": "åˆ†æBERTæ¨¡å‹çš„åˆ›æ–°ç‚¹"},
                    {"role": "assistant", "content": "æ·±å…¥åˆ†æäº†BERTçš„åŒå‘ç¼–ç ã€é¢„è®­ç»ƒç­–ç•¥ã€å¾®è°ƒæ–¹æ³•..."},  # researcher
                    {"role": "assistant", "content": "åŸºäºè¯¦ç»†ç ”ç©¶ï¼Œæ’°å†™äº†åŒ…å«æ¶æ„å›¾ã€ç®—æ³•æµç¨‹ã€æ€§èƒ½å¯¹æ¯”çš„å®Œæ•´æŠ¥å‘Š..."},  # writer
                    {"role": "assistant", "content": "æŠ¥å‘Šç»“æ„æ¸…æ™°ï¼ŒæŠ€æœ¯ç»†èŠ‚å‡†ç¡®ï¼Œå»ºè®®å‘å¸ƒ"},  # reviewer
                ],
                {"score": 0.95, "comment": "å›¢é˜Ÿåä½œå®Œç¾ï¼ŒæŠ¥å‘Šè´¨é‡å¾ˆé«˜"}
            )
        ]
        
        print("ğŸ‘¥ åŸå§‹æ™ºèƒ½ä½“æç¤ºè¯ï¼š")
        for agent in agent_prompts:
            print(f"  {agent['name']}: {agent['prompt']}")
        
        if LANGMEM_AVAILABLE:
            # åˆ›å»ºå¤šæ™ºèƒ½ä½“ä¼˜åŒ–å™¨
            multi_optimizer = create_multi_prompt_optimizer(
                self.model_name,
                kind="gradient",
                config={"max_reflection_steps": 2}
            )
            
            try:
                optimized_prompts = await multi_optimizer.ainvoke({
                    "trajectories": team_conversations,
                    "prompts": agent_prompts
                })
                
                print("\nâœ¨ ä¼˜åŒ–åçš„æ™ºèƒ½ä½“æç¤ºè¯ï¼š")
                for prompt_info in optimized_prompts:
                    print(f"\n{prompt_info['name']}:")
                    print(f"  {prompt_info['prompt']}")
                    
            except Exception as e:
                print(f"âŒ å¤šæ™ºèƒ½ä½“ä¼˜åŒ–å¤±è´¥: {e}")
                self._show_mock_multi_optimization()
        else:
            self._show_mock_multi_optimization()
    
    def _show_mock_multi_optimization(self):
        """æ˜¾ç¤ºæ¨¡æ‹Ÿçš„å¤šæ™ºèƒ½ä½“ä¼˜åŒ–ç»“æœ"""
        mock_optimized_agents = [
            {
                "name": "researcher",
                "prompt": """ä½ æ˜¯ä¸€ä¸ªæ·±åº¦æŠ€æœ¯ç ”ç©¶å‘˜ï¼Œä¸“é—¨è´Ÿè´£æ”¶é›†å’Œåˆ†æå‰æ²¿æŠ€æœ¯ä¿¡æ¯ã€‚åœ¨ç ”ç©¶æ—¶è¯·ï¼š
1. æ·±å…¥æŒ–æ˜æŠ€æœ¯ç»†èŠ‚å’Œå®ç°åŸç†
2. æ”¶é›†æœ€æ–°çš„è®ºæ–‡ã€ä»£ç å’Œå®éªŒæ•°æ®
3. åˆ†ææŠ€æœ¯çš„åˆ›æ–°ç‚¹å’Œå±€é™æ€§
4. æä¾›è¯¦ç»†çš„æŠ€æœ¯æ¶æ„å’Œç®—æ³•æµç¨‹
5. åŒ…å«æ€§èƒ½åŸºå‡†å’Œå¯¹æ¯”åˆ†æ"""
            },
            {
                "name": "writer", 
                "prompt": """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯å†™ä½œä¸“å®¶ï¼Œè´Ÿè´£å°†å¤æ‚çš„ç ”ç©¶ç»“æœè½¬åŒ–ä¸ºæ¸…æ™°ã€ç»“æ„åŒ–çš„æŠ€æœ¯æŠ¥å‘Šã€‚å†™ä½œæ—¶è¯·ï¼š
1. ä½¿ç”¨æ¸…æ™°çš„å±‚æ¬¡ç»“æ„ç»„ç»‡å†…å®¹
2. åŒ…å«æŠ€æœ¯æ¶æ„å›¾å’Œæµç¨‹å›¾
3. æä¾›å…·ä½“çš„ä»£ç ç¤ºä¾‹å’Œå®ç°ç»†èŠ‚
4. æ·»åŠ æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”è¡¨æ ¼
5. ç¡®ä¿æŠ€æœ¯å‡†ç¡®æ€§å’Œå¯è¯»æ€§çš„å¹³è¡¡"""
            },
            {
                "name": "reviewer",
                "prompt": """ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„æŠ€æœ¯è´¨é‡å®¡æ ¸å‘˜ï¼Œè´Ÿè´£ç¡®ä¿æŠ¥å‘Šçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚å®¡æ ¸æ—¶è¯·ï¼š
1. éªŒè¯æŠ€æœ¯ç»†èŠ‚çš„å‡†ç¡®æ€§
2. æ£€æŸ¥æ˜¯å¦é—æ¼é‡è¦çš„æŠ€æœ¯è¦ç‚¹
3. ç¡®è®¤ä»£ç ç¤ºä¾‹çš„æ­£ç¡®æ€§
4. è¯„ä¼°æŠ¥å‘Šçš„é€»è¾‘ç»“æ„å’Œå¯è¯»æ€§
5. æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®"""
            }
        ]
        
        print("\nâœ¨ æ¨¡æ‹Ÿä¼˜åŒ–åçš„æ™ºèƒ½ä½“æç¤ºè¯ï¼š")
        for agent in mock_optimized_agents:
            print(f"\n{agent['name']}:")
            print(f"  {agent['prompt']}")
    
    async def demo_continuous_improvement(self):
        """æ¼”ç¤ºåŸºäºç”¨æˆ·åé¦ˆçš„æŒç»­æ”¹è¿›"""
        print("\n" + "="*60)
        print("ğŸ”„ æŒç»­æ”¹è¿›æ¼”ç¤º")
        print("="*60)
        
        print("ğŸ“Š æ¨¡æ‹ŸæŒç»­æ”¹è¿›æµç¨‹ï¼š")
        
        improvement_steps = [
            {
                "step": 1,
                "description": "æ”¶é›†ç”¨æˆ·åé¦ˆ",
                "data": "ç”¨æˆ·åé¦ˆï¼šå›ç­”å¤ªæŠ€æœ¯åŒ–ï¼Œéœ€è¦æ›´é€šä¿—æ˜“æ‡‚"
            },
            {
                "step": 2, 
                "description": "åˆ†æåé¦ˆæ¨¡å¼",
                "data": "å‘ç°æ¨¡å¼ï¼š80%ç”¨æˆ·å¸Œæœ›æ›´ç®€å•çš„è§£é‡Š"
            },
            {
                "step": 3,
                "description": "ä¼˜åŒ–æç¤ºè¯",
                "data": "æ·»åŠ ï¼š'ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šï¼Œé¿å…è¿‡å¤šä¸“ä¸šæœ¯è¯­'"
            },
            {
                "step": 4,
                "description": "æµ‹è¯•æ–°æç¤ºè¯",
                "data": "A/Bæµ‹è¯•ï¼šæ–°æç¤ºè¯æ»¡æ„åº¦æå‡25%"
            },
            {
                "step": 5,
                "description": "éƒ¨ç½²æ”¹è¿›ç‰ˆæœ¬",
                "data": "æ­£å¼éƒ¨ç½²ï¼Œç»§ç»­æ”¶é›†åé¦ˆ"
            }
        ]
        
        for step in improvement_steps:
            print(f"\næ­¥éª¤ {step['step']}: {step['description']}")
            print(f"  ğŸ“ {step['data']}")
            await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        print("\nâœ… æŒç»­æ”¹è¿›å¾ªç¯å»ºç«‹å®Œæˆï¼")
    
    def show_integration_suggestions(self):
        """æ˜¾ç¤ºé›†æˆå»ºè®®"""
        print("\n" + "="*60)
        print("ğŸ’¡ é¡¹ç›®é›†æˆå»ºè®®")
        print("="*60)
        
        suggestions = [
            {
                "area": "æ™ºèƒ½ä½“ç³»ç»Ÿ",
                "suggestion": "ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“ç±»å‹å»ºç«‹æç¤ºè¯ä¼˜åŒ–æµç¨‹",
                "implementation": "åœ¨core/agents/ä¸­æ·»åŠ prompt_optimizeræ¨¡å—"
            },
            {
                "area": "ç”¨æˆ·åé¦ˆæ”¶é›†",
                "suggestion": "åœ¨APIå“åº”ä¸­æ·»åŠ åé¦ˆæ”¶é›†æœºåˆ¶",
                "implementation": "æ‰©å±•models/chat_models.pyæ·»åŠ åé¦ˆå­—æ®µ"
            },
            {
                "area": "A/Bæµ‹è¯•",
                "suggestion": "å®ç°æç¤ºè¯ç‰ˆæœ¬ç®¡ç†å’ŒA/Bæµ‹è¯•",
                "implementation": "åœ¨core/experiments/ä¸­æ·»åŠ ab_testingæ¨¡å—"
            },
            {
                "area": "ç›‘æ§æŒ‡æ ‡",
                "suggestion": "è·Ÿè¸ªæç¤ºè¯æ€§èƒ½æŒ‡æ ‡",
                "implementation": "æ‰©å±•core/logging/æ·»åŠ prompt_metrics"
            },
            {
                "area": "è‡ªåŠ¨åŒ–ä¼˜åŒ–",
                "suggestion": "å®šæœŸè‡ªåŠ¨ä¼˜åŒ–æç¤ºè¯",
                "implementation": "åœ¨scripts/ä¸­æ·»åŠ auto_optimize_prompts.py"
            }
        ]
        
        for suggestion in suggestions:
            print(f"\nğŸ¯ {suggestion['area']}:")
            print(f"  å»ºè®®: {suggestion['suggestion']}")
            print(f"  å®ç°: {suggestion['implementation']}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LangMem æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½æ¼”ç¤º")
    print("å±•ç¤ºå¦‚ä½•ä½¿ç”¨LangMemè‡ªåŠ¨æ”¹è¿›æ™ºèƒ½ä½“çš„æç¤ºè¯")
    
    if not LANGMEM_AVAILABLE:
        print("\nâš ï¸  æ³¨æ„ï¼šLangMemæœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¼”ç¤º")
        print("å®‰è£…å‘½ä»¤ï¼špip install langmem")
    
    demo = PromptOptimizationDemo()
    
    # æ¼”ç¤ºå„ç§ä¼˜åŒ–åŠŸèƒ½
    await demo.demo_single_agent_optimization()
    await demo.demo_multi_agent_optimization()
    await demo.demo_continuous_improvement()
    
    # æ˜¾ç¤ºé›†æˆå»ºè®®
    demo.show_integration_suggestions()
    
    print("\n" + "="*60)
    print("ğŸ‰ æç¤ºè¯ä¼˜åŒ–æ¼”ç¤ºå®Œæˆï¼")
    print("è¿™ä¸ªåŠŸèƒ½å¯ä»¥æ˜¾è‘—æå‡æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ€§èƒ½")
    print("="*60)


if __name__ == "__main__":
    asyncio.run(main())