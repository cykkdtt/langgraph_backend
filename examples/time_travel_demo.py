#!/usr/bin/env python3
"""
LangGraphæ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º

åŸºäºLangGraphå®˜æ–¹æ–‡æ¡£å®ç°çš„æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤ºï¼ŒåŒ…æ‹¬ï¼š
1. çŠ¶æ€å¿«ç…§å’Œæ£€æŸ¥ç‚¹ç®¡ç†
2. æ—¶é—´æ—…è¡Œå’ŒçŠ¶æ€å›æ»š
3. åˆ†æ”¯æ‰§è¡Œå’ŒçŠ¶æ€ä¿®æ”¹
4. æ‰§è¡Œå†å²æŸ¥è¯¢å’Œåˆ†æ

å‚è€ƒæ–‡æ¡£ï¼š
- https://langchain-ai.github.io/langgraph/concepts/time-travel/
- https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/
"""

import asyncio
import uuid
from typing import TypedDict, Optional, List, Dict, Any
from datetime import datetime
from typing_extensions import NotRequired

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langchain.chat_models import init_chat_model

# å¯¼å…¥é¡¹ç›®çš„æ—¶é—´æ—…è¡Œæ¨¡å—
from core.time_travel import (
    TimeTravelManager, StateHistoryManager,
    TimeTravelConfig, SnapshotType, CheckpointType
)


class JokeState(TypedDict):
    """ç¬‘è¯ç”ŸæˆçŠ¶æ€"""
    topic: NotRequired[str]
    joke: NotRequired[str]
    rating: NotRequired[int]
    feedback: NotRequired[str]
    iteration: NotRequired[int]


class TimeTravelDemo:
    """æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º"""
    
    def __init__(self):
        # åˆå§‹åŒ–LLM
        self.llm = init_chat_model(
            "openai:gpt-4o-mini",
            temperature=0.7,
        )
        
        # åˆå§‹åŒ–æ£€æŸ¥ç‚¹ä¿å­˜å™¨
        self.checkpointer = InMemorySaver()
        
        # åˆå§‹åŒ–æ—¶é—´æ—…è¡Œç®¡ç†å™¨
        self.time_travel_config = TimeTravelConfig(
            auto_snapshot=True,
            snapshot_interval=1,  # æ¯æ­¥éƒ½åˆ›å»ºå¿«ç…§
            auto_checkpoint=True,
            checkpoint_on_milestone=True
        )
        self.time_travel_manager = TimeTravelManager(self.time_travel_config)
        
        # æ„å»ºå›¾
        self.graph = self._build_graph()
        
    def _build_graph(self) -> StateGraph:
        """æ„å»ºç¬‘è¯ç”Ÿæˆå·¥ä½œæµå›¾"""
        workflow = StateGraph(JokeState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("generate_topic", self._generate_topic)
        workflow.add_node("write_joke", self._write_joke)
        workflow.add_node("rate_joke", self._rate_joke)
        workflow.add_node("improve_joke", self._improve_joke)
        
        # æ·»åŠ è¾¹
        workflow.add_edge(START, "generate_topic")
        workflow.add_edge("generate_topic", "write_joke")
        workflow.add_edge("write_joke", "rate_joke")
        workflow.add_edge("rate_joke", "improve_joke")
        workflow.add_edge("improve_joke", END)
        
        return workflow.compile(checkpointer=self.checkpointer)
    
    def _generate_topic(self, state: JokeState) -> JokeState:
        """ç”Ÿæˆç¬‘è¯ä¸»é¢˜"""
        print("ğŸ¯ ç”Ÿæˆç¬‘è¯ä¸»é¢˜...")
        
        msg = self.llm.invoke("ç»™æˆ‘ä¸€ä¸ªæœ‰è¶£çš„ç¬‘è¯ä¸»é¢˜ï¼Œç”¨ä¸­æ–‡å›ç­”")
        topic = msg.content
        
        print(f"ä¸»é¢˜: {topic}")
        return {"topic": topic, "iteration": 1}
    
    def _write_joke(self, state: JokeState) -> JokeState:
        """æ ¹æ®ä¸»é¢˜å†™ç¬‘è¯"""
        print(f"âœï¸ æ ¹æ®ä¸»é¢˜'{state['topic']}'å†™ç¬‘è¯...")
        
        prompt = f"æ ¹æ®ä¸»é¢˜'{state['topic']}'å†™ä¸€ä¸ªç®€çŸ­æœ‰è¶£çš„ç¬‘è¯ï¼Œç”¨ä¸­æ–‡å›ç­”"
        msg = self.llm.invoke(prompt)
        joke = msg.content
        
        print(f"ç¬‘è¯: {joke}")
        return {"joke": joke}
    
    def _rate_joke(self, state: JokeState) -> JokeState:
        """è¯„ä»·ç¬‘è¯è´¨é‡"""
        print("â­ è¯„ä»·ç¬‘è¯è´¨é‡...")
        
        prompt = f"è¯·å¯¹è¿™ä¸ªç¬‘è¯è¿›è¡Œè¯„åˆ†(1-10åˆ†)å¹¶ç»™å‡ºç®€çŸ­è¯„ä»·ï¼š\n{state['joke']}\nåªè¿”å›æ•°å­—åˆ†æ•°å’Œä¸€å¥è¯è¯„ä»·ï¼Œæ ¼å¼ï¼šåˆ†æ•°|è¯„ä»·"
        msg = self.llm.invoke(prompt)
        response = msg.content
        
        try:
            parts = response.split('|')
            rating = int(parts[0].strip())
            feedback = parts[1].strip() if len(parts) > 1 else "æ— è¯„ä»·"
        except:
            rating = 5
            feedback = "è¯„ä»·è§£æå¤±è´¥"
        
        print(f"è¯„åˆ†: {rating}/10")
        print(f"è¯„ä»·: {feedback}")
        
        return {"rating": rating, "feedback": feedback}
    
    def _improve_joke(self, state: JokeState) -> JokeState:
        """æ”¹è¿›ç¬‘è¯"""
        if state.get("rating", 0) >= 8:
            print("âœ… ç¬‘è¯è´¨é‡å¾ˆå¥½ï¼Œæ— éœ€æ”¹è¿›")
            return state
        
        print("ğŸ”§ æ”¹è¿›ç¬‘è¯...")
        
        prompt = f"""
        è¯·æ”¹è¿›è¿™ä¸ªç¬‘è¯ï¼Œä½¿å…¶æ›´æœ‰è¶£ï¼š
        åŸç¬‘è¯: {state['joke']}
        è¯„ä»·: {state['feedback']}
        
        è¯·å†™ä¸€ä¸ªæ”¹è¿›ç‰ˆæœ¬ï¼Œç”¨ä¸­æ–‡å›ç­”
        """
        
        msg = self.llm.invoke(prompt)
        improved_joke = msg.content
        
        print(f"æ”¹è¿›åçš„ç¬‘è¯: {improved_joke}")
        
        iteration = state.get("iteration", 1) + 1
        return {"joke": improved_joke, "iteration": iteration}

    async def run_basic_demo(self):
        """è¿è¡ŒåŸºç¡€æ¼”ç¤º"""
        print("=" * 60)
        print("ğŸš€ å¼€å§‹åŸºç¡€ç¬‘è¯ç”Ÿæˆæ¼”ç¤º")
        print("=" * 60)
        
        # åˆ›å»ºé…ç½®
        config = {
            "configurable": {
                "thread_id": str(uuid.uuid4()),
            }
        }
        
        # è¿è¡Œå›¾
        result = self.graph.invoke({}, config)
        
        print("\nğŸ“Š æœ€ç»ˆç»“æœ:")
        print(f"ä¸»é¢˜: {result.get('topic', 'N/A')}")
        print(f"ç¬‘è¯: {result.get('joke', 'N/A')}")
        print(f"è¯„åˆ†: {result.get('rating', 'N/A')}/10")
        print(f"è¿­ä»£æ¬¡æ•°: {result.get('iteration', 'N/A')}")
        
        return config, result

    async def demonstrate_time_travel(self, config: Dict[str, Any]):
        """æ¼”ç¤ºæ—¶é—´æ—…è¡ŒåŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("â° æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤º")
        print("=" * 60)
        
        # 1. è·å–æ‰§è¡Œå†å² <mcreference link="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/" index="1">1</mcreference>
        print("\nğŸ“œ è·å–æ‰§è¡Œå†å²:")
        states = list(self.graph.get_state_history(config))
        
        for i, state in enumerate(states):
            print(f"  {i+1}. æ£€æŸ¥ç‚¹: {state.config['configurable']['checkpoint_id'][:8]}...")
            print(f"     ä¸‹ä¸€æ­¥: {state.next}")
            if state.values:
                topic = state.values.get('topic', 'N/A')[:30]
                joke = state.values.get('joke', 'N/A')[:50]
                print(f"     ä¸»é¢˜: {topic}...")
                print(f"     ç¬‘è¯: {joke}...")
            print()
        
        # 2. é€‰æ‹©ä¸€ä¸ªæ£€æŸ¥ç‚¹è¿›è¡Œæ—¶é—´æ—…è¡Œ <mcreference link="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/" index="1">1</mcreference>
        if len(states) >= 2:
            selected_state = states[1]  # é€‰æ‹©ç¬¬äºŒä¸ªçŠ¶æ€ï¼ˆç”Ÿæˆä¸»é¢˜åï¼‰
            print(f"ğŸ¯ é€‰æ‹©æ£€æŸ¥ç‚¹è¿›è¡Œæ—¶é—´æ—…è¡Œ:")
            print(f"   æ£€æŸ¥ç‚¹ID: {selected_state.config['configurable']['checkpoint_id']}")
            print(f"   ä¸‹ä¸€æ­¥: {selected_state.next}")
            print(f"   çŠ¶æ€: {selected_state.values}")
            
            # 3. ä¿®æ”¹çŠ¶æ€å¹¶ä»æ£€æŸ¥ç‚¹æ¢å¤ <mcreference link="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/" index="1">1</mcreference>
            print("\nğŸ”„ ä¿®æ”¹çŠ¶æ€å¹¶ä»æ£€æŸ¥ç‚¹æ¢å¤:")
            new_config = self.graph.update_state(
                config,
                {"topic": "ç¨‹åºå‘˜å’ŒBugçš„çˆ±æ¨æƒ…ä»‡"},
                checkpoint_id=selected_state.config["configurable"]["checkpoint_id"]
            )
            
            print(f"   æ–°æ£€æŸ¥ç‚¹ID: {new_config['configurable']['checkpoint_id']}")
            
            # 4. ä»ä¿®æ”¹åçš„çŠ¶æ€ç»§ç»­æ‰§è¡Œ <mcreference link="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/" index="1">1</mcreference>
            print("\nâ–¶ï¸ ä»ä¿®æ”¹åçš„çŠ¶æ€ç»§ç»­æ‰§è¡Œ:")
            alternative_result = self.graph.invoke(
                None,  # è¾“å…¥ä¸ºNoneè¡¨ç¤ºä»æ£€æŸ¥ç‚¹ç»§ç»­
                new_config
            )
            
            print("\nğŸ“Š æ›¿ä»£æ—¶é—´çº¿çš„ç»“æœ:")
            print(f"ä¸»é¢˜: {alternative_result.get('topic', 'N/A')}")
            print(f"ç¬‘è¯: {alternative_result.get('joke', 'N/A')}")
            print(f"è¯„åˆ†: {alternative_result.get('rating', 'N/A')}/10")
            
            # 5. æ¯”è¾ƒä¸¤ä¸ªæ—¶é—´çº¿ <mcreference link="https://langchain-ai.github.io/langgraph/concepts/time-travel/" index="0">0</mcreference>
            print("\nğŸ” æ—¶é—´çº¿æ¯”è¾ƒ:")
            print("åŸå§‹æ—¶é—´çº¿ vs æ›¿ä»£æ—¶é—´çº¿")
            print("-" * 40)
            
            # è·å–ä¸¤ä¸ªæ—¶é—´çº¿çš„æœ€ç»ˆçŠ¶æ€
            original_states = list(self.graph.get_state_history(config))
            alternative_states = list(self.graph.get_state_history(new_config))
            
            if original_states and alternative_states:
                orig_final = original_states[0].values
                alt_final = alternative_states[0].values
                
                print(f"ä¸»é¢˜: '{orig_final.get('topic', 'N/A')}' -> '{alt_final.get('topic', 'N/A')}'")
                print(f"è¯„åˆ†: {orig_final.get('rating', 'N/A')} -> {alt_final.get('rating', 'N/A')}")
                
            return new_config, alternative_result
        
        return None, None

    async def demonstrate_branching(self, config: Dict[str, Any]):
        """æ¼”ç¤ºåˆ†æ”¯åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸŒ³ åˆ†æ”¯æ‰§è¡Œæ¼”ç¤º")
        print("=" * 60)
        
        # è·å–å†å²çŠ¶æ€
        states = list(self.graph.get_state_history(config))
        if len(states) < 2:
            print("âŒ å†å²çŠ¶æ€ä¸è¶³ï¼Œæ— æ³•æ¼”ç¤ºåˆ†æ”¯åŠŸèƒ½")
            return
        
        # ä»åŒä¸€ä¸ªæ£€æŸ¥ç‚¹åˆ›å»ºå¤šä¸ªåˆ†æ”¯ <mcreference link="https://langchain-ai.github.io/langgraph/concepts/time-travel/" index="0">0</mcreference>
        base_state = states[1]  # é€‰æ‹©åŸºç¡€çŠ¶æ€
        
        print(f"ğŸ¯ ä»æ£€æŸ¥ç‚¹åˆ›å»ºå¤šä¸ªåˆ†æ”¯:")
        print(f"   åŸºç¡€æ£€æŸ¥ç‚¹: {base_state.config['configurable']['checkpoint_id'][:8]}...")
        
        # åˆ›å»ºåˆ†æ”¯1ï¼šç§‘æŠ€ä¸»é¢˜
        branch1_config = self.graph.update_state(
            config,
            {"topic": "äººå·¥æ™ºèƒ½çš„æ—¥å¸¸ç”Ÿæ´»"},
            checkpoint_id=base_state.config["configurable"]["checkpoint_id"]
        )
        
        # åˆ›å»ºåˆ†æ”¯2ï¼šç”Ÿæ´»ä¸»é¢˜
        branch2_config = self.graph.update_state(
            config,
            {"topic": "å‡è‚¥è·¯ä¸Šçš„å¥‡é‡"},
            checkpoint_id=base_state.config["configurable"]["checkpoint_id"]
        )
        
        print("\nğŸŒ¿ åˆ†æ”¯1 - ç§‘æŠ€ä¸»é¢˜:")
        branch1_result = self.graph.invoke(None, branch1_config)
        print(f"   ä¸»é¢˜: {branch1_result.get('topic', 'N/A')}")
        print(f"   ç¬‘è¯: {branch1_result.get('joke', 'N/A')[:100]}...")
        print(f"   è¯„åˆ†: {branch1_result.get('rating', 'N/A')}/10")
        
        print("\nğŸŒ¿ åˆ†æ”¯2 - ç”Ÿæ´»ä¸»é¢˜:")
        branch2_result = self.graph.invoke(None, branch2_config)
        print(f"   ä¸»é¢˜: {branch2_result.get('topic', 'N/A')}")
        print(f"   ç¬‘è¯: {branch2_result.get('joke', 'N/A')[:100]}...")
        print(f"   è¯„åˆ†: {branch2_result.get('rating', 'N/A')}/10")
        
        # åˆ†æåˆ†æ”¯ç»“æœ
        print("\nğŸ“ˆ åˆ†æ”¯åˆ†æ:")
        ratings = [
            branch1_result.get('rating', 0),
            branch2_result.get('rating', 0)
        ]
        best_branch = 1 if ratings[0] > ratings[1] else 2
        print(f"   æœ€ä½³åˆ†æ”¯: åˆ†æ”¯{best_branch} (è¯„åˆ†: {max(ratings)}/10)")
        
        return [branch1_config, branch2_config], [branch1_result, branch2_result]

    async def demonstrate_debugging(self, config: Dict[str, Any]):
        """æ¼”ç¤ºè°ƒè¯•åŠŸèƒ½"""
        print("\n" + "=" * 60)
        print("ğŸ è°ƒè¯•åŠŸèƒ½æ¼”ç¤º")
        print("=" * 60)
        
        # åˆ†ææ‰§è¡Œè·¯å¾„ <mcreference link="https://langchain-ai.github.io/langgraph/concepts/time-travel/" index="0">0</mcreference>
        print("ğŸ” åˆ†ææ‰§è¡Œè·¯å¾„:")
        states = list(self.graph.get_state_history(config))
        
        for i, state in enumerate(reversed(states)):
            step_num = i + 1
            checkpoint_id = state.config['configurable']['checkpoint_id'][:8]
            next_step = state.next[0] if state.next else "END"
            
            print(f"   æ­¥éª¤ {step_num}: {next_step} (æ£€æŸ¥ç‚¹: {checkpoint_id}...)")
            
            # æ˜¾ç¤ºå…³é”®çŠ¶æ€å˜åŒ–
            if state.values:
                if 'topic' in state.values and i == 1:
                    print(f"      âœ“ ç”Ÿæˆä¸»é¢˜: {state.values['topic'][:50]}...")
                elif 'joke' in state.values and i == 2:
                    print(f"      âœ“ ç”Ÿæˆç¬‘è¯: {state.values['joke'][:50]}...")
                elif 'rating' in state.values and i == 3:
                    print(f"      âœ“ è¯„åˆ†: {state.values['rating']}/10")
        
        # æ€§èƒ½åˆ†æ
        print("\nâš¡ æ€§èƒ½åˆ†æ:")
        if len(states) > 1:
            total_steps = len(states)
            print(f"   æ€»æ­¥éª¤æ•°: {total_steps}")
            print(f"   å¹³å‡æ¯æ­¥è€—æ—¶: ~0.5ç§’ (æ¨¡æ‹Ÿ)")
            
            # æ‰¾å‡ºå¯èƒ½çš„ä¼˜åŒ–ç‚¹
            final_state = states[0].values
            if final_state.get('rating', 0) < 7:
                print("   ğŸ’¡ ä¼˜åŒ–å»ºè®®: ç¬‘è¯è´¨é‡è¾ƒä½ï¼Œå¯èƒ½éœ€è¦æ”¹è¿›æç¤ºè¯")
            if final_state.get('iteration', 1) > 2:
                print("   ğŸ’¡ ä¼˜åŒ–å»ºè®®: è¿­ä»£æ¬¡æ•°è¾ƒå¤šï¼Œè€ƒè™‘ä¼˜åŒ–åˆå§‹ç”Ÿæˆè´¨é‡")

    async def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸ­ LangGraphæ—¶é—´æ—…è¡ŒåŠŸèƒ½å®Œæ•´æ¼”ç¤º")
        print("åŸºäºå®˜æ–¹æ–‡æ¡£å®ç°çš„æ—¶é—´æ—…è¡Œã€åˆ†æ”¯å’Œè°ƒè¯•åŠŸèƒ½")
        print("=" * 80)
        
        try:
            # 1. åŸºç¡€æ¼”ç¤º
            config, result = await self.run_basic_demo()
            
            # 2. æ—¶é—´æ—…è¡Œæ¼”ç¤º
            alt_config, alt_result = await self.demonstrate_time_travel(config)
            
            # 3. åˆ†æ”¯æ¼”ç¤º
            if alt_config:
                branch_configs, branch_results = await self.demonstrate_branching(alt_config)
            
            # 4. è°ƒè¯•æ¼”ç¤º
            await self.demonstrate_debugging(config)
            
            print("\n" + "=" * 80)
            print("âœ… æ—¶é—´æ—…è¡ŒåŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
            print("\nğŸ¯ æ¼”ç¤ºè¦ç‚¹æ€»ç»“:")
            print("1. âœ“ çŠ¶æ€å¿«ç…§å’Œæ£€æŸ¥ç‚¹ç®¡ç†")
            print("2. âœ“ æ—¶é—´æ—…è¡Œå’ŒçŠ¶æ€å›æ»š")
            print("3. âœ“ åˆ†æ”¯æ‰§è¡Œå’ŒçŠ¶æ€ä¿®æ”¹")
            print("4. âœ“ æ‰§è¡Œå†å²æŸ¥è¯¢å’Œè°ƒè¯•")
            print("\nğŸ“š å‚è€ƒæ–‡æ¡£:")
            print("- LangGraphæ—¶é—´æ—…è¡Œæ¦‚å¿µ: https://langchain-ai.github.io/langgraph/concepts/time-travel/")
            print("- æ—¶é—´æ—…è¡Œä½¿ç”¨æŒ‡å—: https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/")
            
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    demo = TimeTravelDemo()
    await demo.run_complete_demo()


if __name__ == "__main__":
    asyncio.run(main())